import streamlit as st
import os
import logging
from datetime import datetime
import pandas as pd
import numpy as np
import sys
import asyncio
import requests
import json
import time
import uuid
from typing import Dict, List, Any, Optional
import nest_asyncio
import platform
import subprocess
import glob  # æ·»åŠ globå¯¼å…¥
import shutil
from manage_projects import delete_project as manage_delete_project
import re
from sentence_transformers import SentenceTransformer
import io
import csv
import functools  # Import functools for cache clearing if needed

# æ·»åŠ fixed_dimension_editorä¸­å‡½æ•°çš„å¯¼å…¥
from fixed_dimension_editor import (
    render_dimension_editor, apply_template, save_template, 
    delete_template, get_template_names
)

# é˜¿é‡Œäº‘DashScopeçƒ­è¯ç®¡ç†APIæ¥å£
def create_vocabulary(prefix, target_model, vocabulary):
    """åˆ›å»ºçƒ­è¯è¡¨"""
    # ç›´æ¥ä½¿ç”¨APIå¯†é’¥ï¼Œé¿å…ç¯å¢ƒå˜é‡é—®é¢˜
    api_key = 'sk-fb02b49dcf5445ebada6d4ba70b1f8f1'
    if not api_key:
        logger.error("ç¼ºå°‘DASHSCOPE_API_KEYç¯å¢ƒå˜é‡")
        raise ValueError("ç¼ºå°‘DASHSCOPE_API_KEYç¯å¢ƒå˜é‡")
        
    url = "https://dashscope.aliyuncs.com/api/v1/services/audio/asr/customization"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    data = {
        "model": "speech-biasing",
        "input": {
            "action": "create_vocabulary",
            "target_model": target_model,
            "prefix": prefix,
            "vocabulary": vocabulary
        }
    }
    
    logger.info(f"å‡†å¤‡å‘é€çƒ­è¯è¡¨åˆ›å»ºè¯·æ±‚ï¼Œå‰ç¼€: {prefix}, æ¨¡å‹: {target_model}, çƒ­è¯æ•°é‡: {len(vocabulary)}")
    
    try:
        # è®¾ç½®åˆç†çš„è¶…æ—¶æ—¶é—´ï¼Œæ·»åŠ æ›´å¥å£®çš„é”™è¯¯å¤„ç†
        response = requests.post(url, headers=headers, json=data, timeout=(5, 30))
        response.raise_for_status()
        result = response.json()
        
        if 'output' in result and 'task_id' in result['output']:
            logger.info(f"çƒ­è¯è¡¨åˆ›å»ºä»»åŠ¡å·²æäº¤ï¼Œä»»åŠ¡ID: {result['output']['task_id']}")
        else:
            error_code = result.get('code', 'æœªçŸ¥é”™è¯¯ç ')
            error_message = result.get('message', 'æœªçŸ¥é”™è¯¯')
            logger.error(f"çƒ­è¯è¡¨åˆ›å»ºå¤±è´¥, é”™è¯¯ç : {error_code}, é”™è¯¯ä¿¡æ¯: {error_message}")
            
            # è®°å½•ç‰¹å®šé”™è¯¯ç çš„è¯¦ç»†ä¿¡æ¯
            if error_code == 'InvalidApiKey':
                logger.error("APIå¯†é’¥æ— æ•ˆï¼Œè¯·æ£€æŸ¥DASHSCOPE_API_KEYç¯å¢ƒå˜é‡")
            elif error_code == 'QuotaExceeded':
                logger.error("å·²è¶…å‡ºAPIé…é¢é™åˆ¶ï¼Œè¯·è”ç³»é˜¿é‡Œäº‘å®¢æœ")
            elif error_code == 'AccessDenied':
                logger.error("æ²¡æœ‰è®¿é—®æƒé™ï¼Œè¯·ç¡®è®¤è´¦æˆ·æ˜¯å¦å¼€é€šäº†ç›¸å…³æœåŠ¡")
            elif error_code == 'InvalidParameter':
                logger.error(f"å‚æ•°é”™è¯¯: {error_message}")
            
        return result
        
    except requests.exceptions.HTTPError as http_err:
        logger.error(f"HTTPé”™è¯¯: {http_err}")
        status_code = getattr(http_err.response, 'status_code', None)
        logger.error(f"çŠ¶æ€ç : {status_code}")
        try:
            error_json = http_err.response.json()
            logger.error(f"é”™è¯¯è¯¦æƒ…: {error_json}")
            return error_json
        except:
            return {"code": "HTTPError", "message": str(http_err)}
            
    except requests.exceptions.ConnectionError as conn_err:
        logger.error(f"è¿æ¥é”™è¯¯: {conn_err}")
        return {"code": "ConnectionError", "message": "æ— æ³•è¿æ¥åˆ°é˜¿é‡Œäº‘æœåŠ¡ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥"}
        
    except requests.exceptions.Timeout as timeout_err:
        logger.error(f"è¯·æ±‚è¶…æ—¶: {timeout_err}")
        return {"code": "TimeoutError", "message": "è¯·æ±‚è¶…æ—¶ï¼Œè¯·ç¨åå†è¯•"}
        
    except requests.exceptions.ProxyError as proxy_err:
        logger.error(f"ä»£ç†é”™è¯¯: {proxy_err}")
        return {"code": "ProxyError", "message": "ä»£ç†æœåŠ¡å™¨é”™è¯¯ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè®¾ç½®æˆ–ç¦ç”¨ä»£ç†"}
        
    except requests.exceptions.SSLError as ssl_err:
        logger.error(f"SSLé”™è¯¯: {ssl_err}")
        return {"code": "SSLError", "message": "SSLè¯ä¹¦éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œç¯å¢ƒ"}
        
    except requests.exceptions.JSONDecodeError as json_err:
        logger.error(f"JSONè§£æé”™è¯¯: {json_err}")
        return {"code": "JSONDecodeError", "message": "æ— æ³•è§£æAPIå“åº”"}
        
    except Exception as e:
        logger.error(f"åˆ›å»ºçƒ­è¯è¡¨æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}", exc_info=True)
        return {"code": "UnknownError", "message": str(e)}

def list_vocabulary(prefix=None, page_index=0, page_size=10):
    """æŸ¥è¯¢æ‰€æœ‰çƒ­è¯è¡¨"""
    # ç›´æ¥ä½¿ç”¨APIå¯†é’¥ï¼Œé¿å…ç¯å¢ƒå˜é‡é—®é¢˜
    api_key = 'sk-fb02b49dcf5445ebada6d4ba70b1f8f1'
    if not api_key:
        logger.error("ç¼ºå°‘DASHSCOPE_API_KEYç¯å¢ƒå˜é‡")
        raise ValueError("ç¼ºå°‘DASHSCOPE_API_KEYç¯å¢ƒå˜é‡")
    
    url = "https://dashscope.aliyuncs.com/api/v1/services/audio/asr/customization"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    data = {
        "model": "speech-biasing",
        "input": {
            "action": "list_vocabulary",
            "prefix": prefix,
            "page_index": page_index,
            "page_size": page_size
        }
    }
    
    logger.info(f"å‡†å¤‡è·å–çƒ­è¯è¡¨åˆ—è¡¨ï¼Œå‰ç¼€: {prefix}, é¡µç : {page_index}, æ¯é¡µæ•°é‡: {page_size}")
    
    try:
        response = requests.post(url, headers=headers, json=data)
        response.raise_for_status()
        result = response.json()
        
        if 'output' in result and 'vocabulary_list' in result['output']:
            logger.info(f"æˆåŠŸè·å–çƒ­è¯è¡¨åˆ—è¡¨ï¼Œå…± {len(result['output']['vocabulary_list'])} ä¸ªçƒ­è¯è¡¨")
        else:
            error_code = result.get('code', 'æœªçŸ¥é”™è¯¯ç ')
            error_message = result.get('message', 'æœªçŸ¥é”™è¯¯')
            logger.error(f"è·å–çƒ­è¯è¡¨åˆ—è¡¨å¤±è´¥, é”™è¯¯ç : {error_code}, é”™è¯¯ä¿¡æ¯: {error_message}")
            
        return result
        
    except requests.exceptions.HTTPError as http_err:
        logger.error(f"HTTPé”™è¯¯: {http_err}")
        try:
            error_json = http_err.response.json()
            logger.error(f"é”™è¯¯è¯¦æƒ…: {error_json}")
            return error_json
        except:
            return {"code": "HTTPError", "message": str(http_err)}
            
    except requests.exceptions.ConnectionError as conn_err:
        logger.error(f"è¿æ¥é”™è¯¯: {conn_err}")
        return {"code": "ConnectionError", "message": "æ— æ³•è¿æ¥åˆ°é˜¿é‡Œäº‘æœåŠ¡ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥"}
        
    except requests.exceptions.Timeout as timeout_err:
        logger.error(f"è¯·æ±‚è¶…æ—¶: {timeout_err}")
        return {"code": "TimeoutError", "message": "è¯·æ±‚è¶…æ—¶ï¼Œè¯·ç¨åå†è¯•"}
        
    except requests.exceptions.JSONDecodeError as json_err:
        logger.error(f"JSONè§£æé”™è¯¯: {json_err}")
        return {"code": "JSONDecodeError", "message": "æ— æ³•è§£æAPIå“åº”"}
        
    except Exception as e:
        logger.error(f"è·å–çƒ­è¯è¡¨åˆ—è¡¨æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}", exc_info=True)
        return {"code": "UnknownError", "message": str(e)}

def query_vocabulary(vocabulary_id):
    """æŸ¥è¯¢æŒ‡å®šçƒ­è¯è¡¨"""
    # ç›´æ¥ä½¿ç”¨APIå¯†é’¥ï¼Œé¿å…ç¯å¢ƒå˜é‡é—®é¢˜
    api_key = 'sk-fb02b49dcf5445ebada6d4ba70b1f8f1'
    if not api_key:
        logger.error("ç¼ºå°‘DASHSCOPE_API_KEYç¯å¢ƒå˜é‡")
        raise ValueError("ç¼ºå°‘DASHSCOPE_API_KEYç¯å¢ƒå˜é‡")
    
    url = "https://dashscope.aliyuncs.com/api/v1/services/audio/asr/customization"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    data = {
        "model": "speech-biasing",
        "input": {
            "action": "query_vocabulary",
            "vocabulary_id": vocabulary_id
        }
    }
    
    logger.info(f"å‡†å¤‡æŸ¥è¯¢çƒ­è¯è¡¨è¯¦æƒ…ï¼Œè¯æ±‡è¡¨ID: {vocabulary_id}")
    
    try:
        response = requests.post(url, headers=headers, json=data)
        response.raise_for_status()
        result = response.json()
        
        if 'output' in result:
            logger.info(f"æˆåŠŸè·å–çƒ­è¯è¡¨è¯¦æƒ…ï¼Œè¯æ±‡è¡¨ID: {vocabulary_id}")
            
            # è®°å½•çƒ­è¯æ•°é‡ç­‰å…³é”®ä¿¡æ¯
            if 'vocabulary' in result['output']:
                hot_words_count = len(result['output'].get('vocabulary', []))
                logger.info(f"çƒ­è¯è¡¨åŒ…å« {hot_words_count} ä¸ªçƒ­è¯")
        else:
            error_code = result.get('code', 'æœªçŸ¥é”™è¯¯ç ')
            error_message = result.get('message', 'æœªçŸ¥é”™è¯¯')
            logger.error(f"è·å–çƒ­è¯è¡¨è¯¦æƒ…å¤±è´¥, è¯æ±‡è¡¨ID: {vocabulary_id}, é”™è¯¯ç : {error_code}, é”™è¯¯ä¿¡æ¯: {error_message}")
            
        return result
        
    except requests.exceptions.HTTPError as http_err:
        logger.error(f"HTTPé”™è¯¯: {http_err}")
        try:
            error_json = http_err.response.json()
            logger.error(f"é”™è¯¯è¯¦æƒ…: {error_json}")
            return error_json
        except:
            return {"code": "HTTPError", "message": str(http_err)}
            
    except requests.exceptions.ConnectionError as conn_err:
        logger.error(f"è¿æ¥é”™è¯¯: {conn_err}")
        return {"code": "ConnectionError", "message": "æ— æ³•è¿æ¥åˆ°é˜¿é‡Œäº‘æœåŠ¡ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥"}
        
    except requests.exceptions.Timeout as timeout_err:
        logger.error(f"è¯·æ±‚è¶…æ—¶: {timeout_err}")
        return {"code": "TimeoutError", "message": "è¯·æ±‚è¶…æ—¶ï¼Œè¯·ç¨åå†è¯•"}
        
    except requests.exceptions.JSONDecodeError as json_err:
        logger.error(f"JSONè§£æé”™è¯¯: {json_err}")
        return {"code": "JSONDecodeError", "message": "æ— æ³•è§£æAPIå“åº”"}
        
    except Exception as e:
        logger.error(f"æŸ¥è¯¢çƒ­è¯è¡¨è¯¦æƒ…æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}", exc_info=True)
        return {"code": "UnknownError", "message": str(e)}

def update_vocabulary(vocabulary_id, vocabulary):
    """æ›´æ–°çƒ­è¯è¡¨"""
    # ç›´æ¥ä½¿ç”¨APIå¯†é’¥ï¼Œé¿å…ç¯å¢ƒå˜é‡é—®é¢˜
    api_key = 'sk-fb02b49dcf5445ebada6d4ba70b1f8f1'
    if not api_key:
        logger.error("ç¼ºå°‘DASHSCOPE_API_KEYç¯å¢ƒå˜é‡")
        raise ValueError("ç¼ºå°‘DASHSCOPE_API_KEYç¯å¢ƒå˜é‡")
    
    url = "https://dashscope.aliyuncs.com/api/v1/services/audio/asr/customization"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    data = {
        "model": "speech-biasing",
        "input": {
            "action": "update_vocabulary",
            "vocabulary_id": vocabulary_id,
            "vocabulary": vocabulary
        }
    }
    
    logger.info(f"å‡†å¤‡æ›´æ–°çƒ­è¯è¡¨ï¼Œè¯æ±‡è¡¨ID: {vocabulary_id}, çƒ­è¯æ•°é‡: {len(vocabulary)}")
    
    try:
        response = requests.post(url, headers=headers, json=data)
        response.raise_for_status()
        result = response.json()
        
        if 'output' in result and 'task_id' in result['output']:
            logger.info(f"çƒ­è¯è¡¨æ›´æ–°ä»»åŠ¡å·²æäº¤ï¼Œä»»åŠ¡ID: {result['output']['task_id']}")
        else:
            error_code = result.get('code', 'æœªçŸ¥é”™è¯¯ç ')
            error_message = result.get('message', 'æœªçŸ¥é”™è¯¯')
            logger.error(f"æ›´æ–°çƒ­è¯è¡¨å¤±è´¥, è¯æ±‡è¡¨ID: {vocabulary_id}, é”™è¯¯ç : {error_code}, é”™è¯¯ä¿¡æ¯: {error_message}")
            
        return result
        
    except requests.exceptions.HTTPError as http_err:
        logger.error(f"HTTPé”™è¯¯: {http_err}")
        try:
            error_json = http_err.response.json()
            logger.error(f"é”™è¯¯è¯¦æƒ…: {error_json}")
            return error_json
        except:
            return {"code": "HTTPError", "message": str(http_err)}
            
    except requests.exceptions.ConnectionError as conn_err:
        logger.error(f"è¿æ¥é”™è¯¯: {conn_err}")
        return {"code": "ConnectionError", "message": "æ— æ³•è¿æ¥åˆ°é˜¿é‡Œäº‘æœåŠ¡ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥"}
        
    except requests.exceptions.Timeout as timeout_err:
        logger.error(f"è¯·æ±‚è¶…æ—¶: {timeout_err}")
        return {"code": "TimeoutError", "message": "è¯·æ±‚è¶…æ—¶ï¼Œè¯·ç¨åå†è¯•"}
        
    except requests.exceptions.JSONDecodeError as json_err:
        logger.error(f"JSONè§£æé”™è¯¯: {json_err}")
        return {"code": "JSONDecodeError", "message": "æ— æ³•è§£æAPIå“åº”"}
        
    except Exception as e:
        logger.error(f"æ›´æ–°çƒ­è¯è¡¨æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}", exc_info=True)
        return {"code": "UnknownError", "message": str(e)}

def delete_vocabulary(vocabulary_id):
    """åˆ é™¤çƒ­è¯è¡¨"""
    # ç›´æ¥ä½¿ç”¨APIå¯†é’¥ï¼Œé¿å…ç¯å¢ƒå˜é‡é—®é¢˜
    api_key = 'sk-fb02b49dcf5445ebada6d4ba70b1f8f1'
    if not api_key:
        logger.error("ç¼ºå°‘DASHSCOPE_API_KEYç¯å¢ƒå˜é‡")
        raise ValueError("ç¼ºå°‘DASHSCOPE_API_KEYç¯å¢ƒå˜é‡")
    
    url = "https://dashscope.aliyuncs.com/api/v1/services/audio/asr/customization"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    data = {
        "model": "speech-biasing",
        "input": {
            "action": "delete_vocabulary",
            "vocabulary_id": vocabulary_id
        }
    }
    
    logger.info(f"å‡†å¤‡åˆ é™¤çƒ­è¯è¡¨ï¼Œè¯æ±‡è¡¨ID: {vocabulary_id}")
    
    try:
        response = requests.post(url, headers=headers, json=data)
        response.raise_for_status()
        result = response.json()
        
        if 'output' in result:
            logger.info(f"æˆåŠŸåˆ é™¤çƒ­è¯è¡¨ï¼Œè¯æ±‡è¡¨ID: {vocabulary_id}")
        else:
            error_code = result.get('code', 'æœªçŸ¥é”™è¯¯ç ')
            error_message = result.get('message', 'æœªçŸ¥é”™è¯¯')
            logger.error(f"åˆ é™¤çƒ­è¯è¡¨å¤±è´¥, è¯æ±‡è¡¨ID: {vocabulary_id}, é”™è¯¯ç : {error_code}, é”™è¯¯ä¿¡æ¯: {error_message}")
            
            # è®°å½•ç‰¹å®šé”™è¯¯ç çš„è¯¦ç»†ä¿¡æ¯
            if error_code == 'ResourceNotFound':
                logger.error(f"æ‰¾ä¸åˆ°æŒ‡å®šçš„çƒ­è¯è¡¨: {vocabulary_id}")
            elif error_code == 'InvalidApiKey':
                logger.error("APIå¯†é’¥æ— æ•ˆï¼Œè¯·æ£€æŸ¥DASHSCOPE_API_KEYç¯å¢ƒå˜é‡")
            elif error_code == 'AccessDenied':
                logger.error("æ²¡æœ‰è®¿é—®æƒé™ï¼Œè¯·ç¡®è®¤è´¦æˆ·æ˜¯å¦å¼€é€šäº†ç›¸å…³æœåŠ¡")
            
        return result
        
    except requests.exceptions.HTTPError as http_err:
        logger.error(f"HTTPé”™è¯¯: {http_err}")
        try:
            error_json = http_err.response.json()
            logger.error(f"é”™è¯¯è¯¦æƒ…: {error_json}")
            return error_json
        except:
            return {"code": "HTTPError", "message": str(http_err)}
            
    except requests.exceptions.ConnectionError as conn_err:
        logger.error(f"è¿æ¥é”™è¯¯: {conn_err}")
        return {"code": "ConnectionError", "message": "æ— æ³•è¿æ¥åˆ°é˜¿é‡Œäº‘æœåŠ¡ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥"}
        
    except requests.exceptions.Timeout as timeout_err:
        logger.error(f"è¯·æ±‚è¶…æ—¶: {timeout_err}")
        return {"code": "TimeoutError", "message": "è¯·æ±‚è¶…æ—¶ï¼Œè¯·ç¨åå†è¯•"}
        
    except requests.exceptions.JSONDecodeError as json_err:
        logger.error(f"JSONè§£æé”™è¯¯: {json_err}")
        return {"code": "JSONDecodeError", "message": "æ— æ³•è§£æAPIå“åº”"}
        
    except Exception as e:
        logger.error(f"åˆ é™¤çƒ­è¯è¡¨æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}", exc_info=True)
        return {"code": "UnknownError", "message": str(e)}

# è®¾ç½®äº‹ä»¶å¾ªç¯ç­–ç•¥
if platform.system() == 'Windows':
    asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
else:
    # ä½¿ç”¨nest_asyncioå…è®¸åµŒå¥—ä½¿ç”¨åŒä¸€ä¸ªäº‹ä»¶å¾ªç¯
    nest_asyncio.apply()
    
    # æ›´å¥å£®çš„äº‹ä»¶å¾ªç¯è®¾ç½®
    try:
        # å°è¯•è·å–å½“å‰äº‹ä»¶å¾ªç¯
        try:
            loop = asyncio.get_event_loop()
        except RuntimeError:
            # å¦‚æœæ²¡æœ‰äº‹ä»¶å¾ªç¯ï¼Œåˆ›å»ºä¸€ä¸ªæ–°çš„
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
        
        # å¦‚æœäº‹ä»¶å¾ªç¯å·²å…³é—­ï¼Œåˆ›å»ºä¸€ä¸ªæ–°çš„
        if loop.is_closed():
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
    except Exception as e:
        # å‡ºç°ä»»ä½•é”™è¯¯éƒ½é‡æ–°åˆ›å»ºäº‹ä»¶å¾ªç¯
        logger.error(f"è®¾ç½®äº‹ä»¶å¾ªç¯æ—¶å‡ºé”™: {str(e)}")
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
    
    # è®¾ç½®é€€å‡ºå¤„ç†ä»¥ç¡®ä¿æ­£ç¡®å…³é—­
    import atexit
    def cleanup_resources():
        """æ¸…ç†åº”ç”¨ç¨‹åºèµ„æº"""
        try:
            loop = asyncio.get_event_loop()
            if not loop.is_closed():
                logger.info("å…³é—­äº‹ä»¶å¾ªç¯...")
                loop.close()
        except Exception as e:
            logger.error(f"å…³é—­äº‹ä»¶å¾ªç¯æ—¶å‡ºé”™: {str(e)}")
    
    # æ³¨å†Œé€€å‡ºå¤„ç†å‡½æ•°
    atexit.register(cleanup_resources)

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)

# å¯¼å…¥é¡¹ç›®ç»„ä»¶
from session.state import session_state
from ui.components.dimension_editor_fixed import DimensionEditor
from ui.components.video_preview import VideoPreview
from core.processor import VideoProcessor
from core.composer import VideoComposer, VideoSegment
from config import config

# é…ç½®æ—¥å¿—
os.makedirs('logs', exist_ok=True)
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler(os.path.join('logs', 'app.log'))
    ]
)

logger = logging.getLogger(__name__)

# Use Streamlit's caching to prevent repeated disk scans
@st.cache_data(ttl=60) # Cache for 60 seconds, adjust as needed
def get_projects_from_disk():
    """ä»ç£ç›˜è¯»å–é¡¹ç›®åˆ—è¡¨ (Cached)"""
    projects = []
    try:
        session_dir = os.path.join(os.getcwd(), "data", "session")
        logging.info(f"æ­£åœ¨æ‰«æç›®å½• (ç¼“å­˜å¯èƒ½ç”Ÿæ•ˆ): {session_dir}")

        if not os.path.exists(session_dir):
            os.makedirs(session_dir, exist_ok=True)
            logging.info(f"åˆ›å»ºäº†ç›®å½•: {session_dir}")
            return [] # Return empty list if directory was just created

        files = os.listdir(session_dir)
        settings_files = [f for f in files if f.endswith('_settings.json')]

        for file in settings_files:
            project_name = file.replace("_settings.json", "")
            projects.append(project_name)

        logging.info(f"æ‰¾åˆ° {len(projects)} ä¸ªé¡¹ç›®: {', '.join(projects)}")
        return sorted(projects)
    except Exception as e:
        logging.error(f"è·å–é¡¹ç›®åˆ—è¡¨å¤±è´¥: {str(e)}")
        return [] # Return empty list on error

# åœ¨ get_projects_from_disk å‡½æ•°åæ·»åŠ ä¸€ä¸ªå¼ºåˆ¶åˆ é™¤å‡½æ•°
def force_delete_project(project_name):
    """ç›´æ¥ä½¿ç”¨ç³»ç»Ÿå‘½ä»¤å¼ºåˆ¶åˆ é™¤é¡¹ç›®æ–‡ä»¶"""
    try:
        # è·å–ç»å¯¹è·¯å¾„
        abs_path = os.path.abspath(os.path.join('data', 'session'))
        settings_file = os.path.join(abs_path, f"{project_name}_settings.json")
        results_file = os.path.join(abs_path, f"{project_name}_results.json")
        
        logger.info(f"å‡†å¤‡åˆ é™¤é¡¹ç›® '{project_name}'")
        logger.info(f"è®¾ç½®æ–‡ä»¶è·¯å¾„: {settings_file}")
        logger.info(f"ç»“æœæ–‡ä»¶è·¯å¾„: {results_file}")
        
        # ä½¿ç”¨å¤šç§æ–¹æ³•å°è¯•åˆ é™¤
        success = False
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(settings_file):
            logger.warning(f"è®¾ç½®æ–‡ä»¶ä¸å­˜åœ¨: {settings_file}")
            # å¦‚æœè®¾ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæˆ‘ä»¬è®¤ä¸ºè¿™æ˜¯æˆåŠŸçš„
            success = True
        else:
            # è®°å½•æ–‡ä»¶å±æ€§ä»¥ä¾¿è°ƒè¯•
            try:
                file_stat = os.stat(settings_file)
                logger.info(f"æ–‡ä»¶æƒé™: {oct(file_stat.st_mode)}, æ‹¥æœ‰è€…: {file_stat.st_uid}")
            except Exception as stat_err:
                logger.error(f"æ— æ³•è·å–æ–‡ä»¶å±æ€§: {str(stat_err)}")
            
            # å°è¯•æ–¹æ³•1: ä½¿ç”¨os.remove
            try:
                logger.info("å°è¯•ä½¿ç”¨os.removeåˆ é™¤è®¾ç½®æ–‡ä»¶")
                os.remove(settings_file)
                if not os.path.exists(settings_file):
                    logger.info("æˆåŠŸåˆ é™¤è®¾ç½®æ–‡ä»¶")
                    success = True
                else:
                    logger.warning("æ–‡ä»¶ä»ç„¶å­˜åœ¨ï¼Œå°è¯•å…¶ä»–æ–¹æ³•")
            except PermissionError as perm_err:
                logger.error(f"æƒé™é”™è¯¯: {str(perm_err)}")
                # å°è¯•æ›´æ”¹æ–‡ä»¶æƒé™åå†æ¬¡åˆ é™¤
                try:
                    logger.info("å°è¯•æ›´æ”¹æ–‡ä»¶æƒé™ååˆ é™¤")
                    os.chmod(settings_file, 0o777)
                    os.remove(settings_file)
                    if not os.path.exists(settings_file):
                        logger.info("æƒé™æ›´æ”¹åæˆåŠŸåˆ é™¤è®¾ç½®æ–‡ä»¶")
                        success = True
                    else:
                        logger.warning("æ›´æ”¹æƒé™åï¼Œæ–‡ä»¶ä»ç„¶å­˜åœ¨")
                except Exception as chmod_err:
                    logger.error(f"æ›´æ”¹æƒé™å¹¶åˆ é™¤å¤±è´¥: {str(chmod_err)}")
            except FileNotFoundError:
                logger.info("æ–‡ä»¶å·²ä¸å­˜åœ¨ï¼Œè§†ä¸ºåˆ é™¤æˆåŠŸ")
                success = True
            except Exception as e:
                logger.error(f"ä½¿ç”¨os.removeåˆ é™¤è®¾ç½®æ–‡ä»¶å¤±è´¥: {str(e)}")
        
        # å°è¯•æ–¹æ³•2: ä½¿ç”¨ç³»ç»Ÿå‘½ä»¤(å¦‚æœæ–‡ä»¶ä»ç„¶å­˜åœ¨)
        if os.path.exists(settings_file):
            try:
                logger.info("å°è¯•ä½¿ç”¨ç³»ç»Ÿå‘½ä»¤åˆ é™¤è®¾ç½®æ–‡ä»¶")
                # ä½¿ç”¨subprocessè€Œä¸æ˜¯os.systemä»¥è·å–é”™è¯¯è¾“å‡º
                result = subprocess.run(["rm", "-f", settings_file], 
                                      capture_output=True, text=True, check=False)
                
                if result.returncode != 0:
                    logger.error(f"ç³»ç»Ÿå‘½ä»¤åˆ é™¤å¤±è´¥: {result.stderr}")
                    logger.debug(f"å‘½ä»¤è¾“å‡º: {result.stdout}")
                else:
                    logger.info("ç³»ç»Ÿå‘½ä»¤åˆ é™¤æˆåŠŸ")
                    if os.path.exists(settings_file):
                        logger.warning("å°½ç®¡å‘½ä»¤æˆåŠŸæ‰§è¡Œï¼Œæ–‡ä»¶ä»ç„¶å­˜åœ¨")
                    else:
                        success = True
            except Exception as e:
                logger.error(f"æ‰§è¡Œç³»ç»Ÿå‘½ä»¤å¤±è´¥: {str(e)}")
                
            # å¦‚æœä»ç„¶å­˜åœ¨ï¼Œå°è¯•ä½¿ç”¨shell=Trueå‚æ•°
            if os.path.exists(settings_file):
                try:
                    logger.info("å°è¯•ä½¿ç”¨shell=Trueæ–¹å¼åˆ é™¤è®¾ç½®æ–‡ä»¶")
                    result = subprocess.run(f"rm -f '{settings_file}'", 
                                          shell=True, capture_output=True, text=True, check=False)
                    
                    if result.returncode != 0:
                        logger.error(f"shellå‘½ä»¤åˆ é™¤å¤±è´¥: {result.stderr}")
                        logger.debug(f"å‘½ä»¤è¾“å‡º: {result.stdout}")
                    else:
                        logger.info("shellå‘½ä»¤åˆ é™¤æˆåŠŸ")
                        if os.path.exists(settings_file):
                            logger.warning("å°½ç®¡shellå‘½ä»¤æˆåŠŸæ‰§è¡Œï¼Œæ–‡ä»¶ä»ç„¶å­˜åœ¨")
                        else:
                            success = True
                except Exception as e:
                    logger.error(f"æ‰§è¡Œshellå‘½ä»¤å¤±è´¥: {str(e)}")
        
        # æœ€åå°è¯•ä½¿ç”¨sudoï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if os.path.exists(settings_file):
            try:
                logger.info("å°è¯•ä½¿ç”¨sudoå‘½ä»¤åˆ é™¤è®¾ç½®æ–‡ä»¶")
                # æ³¨æ„ï¼šè¿™éœ€è¦ç”¨æˆ·æœ‰sudoæƒé™ï¼Œè€Œä¸”å¯èƒ½ä¼šè¦æ±‚è¾“å…¥å¯†ç 
                result = subprocess.run(f"sudo rm -f '{settings_file}'", 
                                      shell=True, capture_output=True, text=True, check=False)
                
                if result.returncode != 0:
                    logger.error(f"sudoå‘½ä»¤åˆ é™¤å¤±è´¥: {result.stderr}")
                else:
                    logger.info("sudoå‘½ä»¤åˆ é™¤æˆåŠŸ")
                    success = not os.path.exists(settings_file)
            except Exception as e:
                logger.error(f"æ‰§è¡Œsudoå‘½ä»¤å¤±è´¥: {str(e)}")
        
        # å°è¯•åˆ é™¤ç»“æœæ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if os.path.exists(results_file):
            try:
                logger.info("å°è¯•åˆ é™¤ç»“æœæ–‡ä»¶")
                os.remove(results_file)
                logger.info("æˆåŠŸåˆ é™¤ç»“æœæ–‡ä»¶")
            except PermissionError:
                logger.warning("åˆ é™¤ç»“æœæ–‡ä»¶æ—¶å‡ºç°æƒé™é”™è¯¯ï¼Œå°è¯•å…¶ä»–æ–¹æ³•")
                try:
                    # å°è¯•ä½¿ç”¨ç³»ç»Ÿå‘½ä»¤åˆ é™¤
                    subprocess.run(["rm", "-f", results_file], check=False)
                    if not os.path.exists(results_file):
                        logger.info("ä½¿ç”¨ç³»ç»Ÿå‘½ä»¤æˆåŠŸåˆ é™¤ç»“æœæ–‡ä»¶")
                    else:
                        logger.warning("ç»“æœæ–‡ä»¶åˆ é™¤å¤±è´¥ï¼Œä½†è¿™ä¸å½±å“ä¸»è¦åŠŸèƒ½")
                except Exception as rm_err:
                    logger.error(f"ä½¿ç”¨ç³»ç»Ÿå‘½ä»¤åˆ é™¤ç»“æœæ–‡ä»¶å¤±è´¥: {str(rm_err)}")
            except Exception as e:
                logger.error(f"åˆ é™¤ç»“æœæ–‡ä»¶å¤±è´¥: {str(e)}")
                logger.warning("ç»“æœæ–‡ä»¶åˆ é™¤å¤±è´¥ï¼Œä½†è¿™ä¸å½±å“ä¸»è¦åŠŸèƒ½")
        
        # æ£€æŸ¥æœ€ç»ˆç»“æœ
        if success or not os.path.exists(settings_file):
            logger.info(f"æˆåŠŸåˆ é™¤é¡¹ç›® '{project_name}'")
            return True
        else:
            logger.error(f"æ— æ³•åˆ é™¤é¡¹ç›® '{project_name}'ï¼Œæ–‡ä»¶ä»ç„¶å­˜åœ¨: {settings_file}")
            return False
            
    except Exception as e:
        logger.error(f"åˆ é™¤é¡¹ç›®è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        return False

def main():
    """ä¸»åº”ç”¨å…¥å£"""
    # è®¾ç½®é¡µé¢é…ç½®
    st.set_page_config(
        page_title="AIè§†é¢‘æ™ºèƒ½åˆ†æç³»ç»Ÿ",
        page_icon="ğŸ¬",
        layout="wide",
        initial_sidebar_state="expanded",
    )

    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    session_state.initialize_session()
    
    # åˆå§‹åŒ–å…³é”®è¯ç»“æœçŠ¶æ€
    if 'keyword_results' not in st.session_state:
        st.session_state['keyword_results'] = []
    
    # åˆå§‹åŒ–UIçŠ¶æ€å˜é‡
    if 'show_delete_confirm' not in st.session_state:
        st.session_state['show_delete_confirm'] = False
    if 'show_delete_dialog' not in st.session_state:
        st.session_state['show_delete_dialog'] = False
    if 'deleted_project_name' not in st.session_state:
        st.session_state['deleted_project_name'] = ""
    
    # è‡ªåŠ¨åŠ è½½initial key dimensionsä½œä¸ºé»˜è®¤ç»´åº¦è®¾ç½®
    if 'settings' in st.session_state and not st.session_state.settings.get('dimensions'):
        # å…ˆè®°å½•ä¿®æ”¹å‰çš„çŠ¶æ€
        original_dimensions = st.session_state.settings.get('dimensions', None)
        original_weights = st.session_state.settings.get('weights', None)
        original_custom_dimensions = st.session_state.settings.get('custom_dimensions', None)
        settings_changed = False # åˆå§‹åŒ–æ›´æ”¹æ ‡å¿—

        try:
            # ä½¿ç”¨å½“å‰é¡¹ç›®ç›®å½•çš„è·¯å¾„
            template_path = os.path.join('data', 'dimensions', 'initial_key_dimensions.json')
            if os.path.exists(template_path):
                with open(template_path, 'r', encoding='utf-8') as f:
                    initial_template = json.load(f)
                    
                # å°†æ¨¡æ¿æ·»åŠ åˆ°session_state.templates
                if 'templates' not in st.session_state:
                    st.session_state.templates = {}
                st.session_state.templates['initial key dimensions'] = initial_template
                
                # è®¾ç½®ç»´åº¦æ•°æ®
                initial_dimensions = {
                    'level1': 'å“ç‰Œè®¤çŸ¥',
                    'level2': list(initial_template.keys())
                }
                
                # ä¿å­˜åˆ°session_state
                st.session_state.settings['dimensions'] = initial_dimensions
                
                # ç”Ÿæˆæƒé‡è®¾ç½® - ç®€åŒ–åªåŒ…å«äºŒçº§ç»´åº¦
                weights = {
                    'level1': 1.0,
                    'level2': {}
                }
                
                # ä¸ºäºŒçº§ç»´åº¦è®¾ç½®æƒé‡
                for dim2 in initial_dimensions['level2']:
                    weights['level2'][dim2] = 0.5
                
                st.session_state.settings['weights'] = weights
                st.session_state.settings['custom_dimensions'] = True

                # æ£€æŸ¥è®¾ç½®æ˜¯å¦çœŸçš„å‘ç”Ÿäº†å˜åŒ–
                settings_changed = (
                    st.session_state.settings.get('dimensions') != original_dimensions or
                    st.session_state.settings.get('weights') != original_weights or
                    st.session_state.settings.get('custom_dimensions') != original_custom_dimensions
                )
                
                # åªæœ‰åœ¨è®¾ç½®å‘ç”Ÿå˜åŒ–æ—¶æ‰ä¿å­˜
                if settings_changed:
                    current_project = st.session_state.get('current_project', 'default')
                    if current_project:
                        session_state.save_settings(current_project)
                    logger.info("æˆåŠŸè‡ªåŠ¨åŠ è½½å¹¶ä¿å­˜initial key dimensionsä½œä¸ºé»˜è®¤ç»´åº¦è®¾ç½®")
                else:
                    logger.info("Initial key dimensionså·²å­˜åœ¨æˆ–æœªæ›´æ”¹ï¼Œè·³è¿‡ä¿å­˜")

        except Exception as e:
            logger.error(f"è‡ªåŠ¨åŠ è½½initial key dimensionså¤±è´¥: {str(e)}")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å·²å­˜åœ¨çš„é¡¹ç›®ï¼Œå¦‚æœæ²¡æœ‰åˆ™åˆ›å»ºé»˜è®¤é¡¹ç›®
    project_list = get_projects_from_disk()
    if not project_list:
        logger.info("æ²¡æœ‰æ‰¾åˆ°ä»»ä½•é¡¹ç›®ï¼Œæ­£åœ¨åˆ›å»ºé»˜è®¤é¡¹ç›®...")
        default_project_name = "default"
        # ä¿å­˜é»˜è®¤è®¾ç½®åˆ°æ–°é¡¹ç›®
        if session_state.save_settings(default_project_name):
            logger.info(f"å·²è‡ªåŠ¨åˆ›å»ºé»˜è®¤é¡¹ç›®: {default_project_name}")
            # è®¾ç½®å½“å‰é¡¹ç›®ä¸ºé»˜è®¤é¡¹ç›®
            st.session_state['current_project'] = default_project_name
            # æ˜¾ç¤ºä¸€æ¬¡æ€§æç¤º
            st.session_state['show_default_project_created'] = True
            # Clear cache after creating project
            get_projects_from_disk.clear()
            # Rerun to update the UI with the new project list
            st.rerun()
        else:
            logger.error("åˆ›å»ºé»˜è®¤é¡¹ç›®å¤±è´¥")
    
    # æ˜¾ç¤ºé»˜è®¤é¡¹ç›®åˆ›å»ºçš„æç¤º
    if st.session_state.get('show_default_project_created', False):
        st.info("å·²è‡ªåŠ¨åˆ›å»ºé»˜è®¤é¡¹ç›® 'default'ï¼Œå¯ä»¥å¼€å§‹ä½¿ç”¨ç³»ç»ŸåŠŸèƒ½äº†ï¼æ‚¨ä¹Ÿå¯ä»¥åœ¨ä¾§è¾¹æ åˆ›å»ºè‡ªå®šä¹‰é¡¹ç›®ã€‚")
        # åªæ˜¾ç¤ºä¸€æ¬¡æç¤º
        st.session_state['show_default_project_created'] = False
    
    # ä¾§è¾¹æ å¯¼èˆª
    with st.sidebar:
        st.title("AIè§†é¢‘åˆ†æç³»ç»Ÿ")
        st.caption("æœ¬ç³»ç»Ÿç”¨äºæ™ºèƒ½åˆ†æè§†é¢‘å†…å®¹ï¼Œæå–å…³é”®ç‰‡æ®µå¹¶åˆæˆå®£ä¼ è§†é¢‘ã€‚")
        
        # å¯¼èˆªèœå•
        page = st.radio(
            "å¯¼èˆªèœå•",
            ["çƒ­è¯ç®¡ç†", "ç»´åº¦è®¾ç½®", "è§†é¢‘åˆ†æ", "ç»“æœç®¡ç†"]
        )
        
        # é¡¹ç›®ç®¡ç†åŒºåŸŸ - å‡å°‘ä¸Šæ–¹é—´è·
        st.subheader("é¡¹ç›®ç®¡ç†")
        
        # åŠ è½½é¡¹ç›®éƒ¨åˆ† - æ›´ç²¾ç®€çš„ç•Œé¢
        st.write("**åŠ è½½é¡¹ç›®**")
        
        # è·å–å¯ç”¨é¡¹ç›®åˆ—è¡¨ - ç›´æ¥ä»ç£ç›˜è¯»å–ï¼Œä¸ç”¨ç¼“å­˜
        project_list = get_projects_from_disk()
        
        # ---- æ–°å¢ï¼šè‡ªåŠ¨åŠ è½½ default é¡¹ç›® ----
        if 'default' in project_list and not st.session_state.get('current_project'):
            if session_state.load_settings('default'):
                st.session_state['current_project'] = 'default'
                logger.info("è‡ªåŠ¨åŠ è½½é»˜è®¤é¡¹ç›® 'default'")
                # Rerun might be needed to reflect the loaded state immediately in some cases
                # st.rerun()
            else:
                logger.error("å°è¯•è‡ªåŠ¨åŠ è½½é»˜è®¤é¡¹ç›® 'default' å¤±è´¥")
        # ---- ç»“æŸæ–°å¢ ----
        
        # å¸ƒå±€ï¼šä¸‹æ‹‰æ¡†ã€åŠ è½½æŒ‰é’®å’Œåˆ·æ–°æŒ‰é’®åœ¨åŒä¸€è¡Œ
        col_select, col_load, col_refresh = st.columns([3, 1, 1])
        with col_select:
            # ---- ä¿®æ”¹ï¼šè®¡ç®— selectbox çš„é»˜è®¤ç´¢å¼• ----
            current_project_index = 0
            if project_list: # ç¡®ä¿åˆ—è¡¨ä¸ä¸ºç©º
                current_loaded_project = st.session_state.get('current_project')
                if current_loaded_project and current_loaded_project in project_list:
                    try:
                        current_project_index = project_list.index(current_loaded_project)
                    except ValueError:
                        current_project_index = 0 # å¦‚æœæ‰¾ä¸åˆ°ï¼Œé»˜è®¤ç¬¬ä¸€ä¸ª
                elif 'default' in project_list: # å¦‚æœæ²¡æœ‰åŠ è½½é¡¹ç›®ï¼Œä½† default å­˜åœ¨ï¼Œåˆ™é»˜è®¤é€‰ä¸­ default
                     try:
                        current_project_index = project_list.index('default')
                     except ValueError:
                         current_project_index = 0
            # ---- ç»“æŸä¿®æ”¹ ----

            selected_project = st.selectbox(
                "è¯·é€‰æ‹©è¦åŠ è½½çš„é¡¹ç›®",
                options=project_list,
                # index=0 if project_list else 0, # æ—§çš„ç´¢å¼•é€»è¾‘
                index=current_project_index, # ä½¿ç”¨è®¡ç®—å‡ºçš„ç´¢å¼•
                placeholder="é€‰æ‹©é¡¹ç›®...",
                label_visibility="collapsed"
            )
        
        # åŠ è½½æŒ‰é’®
        with col_load:
            load_clicked = st.button("åŠ è½½", key="load_project")
            
        # åˆ·æ–°æŒ‰é’®
        with col_refresh:
            refresh_clicked = st.button("ğŸ”„", key="refresh_projects", help="åˆ·æ–°é¡¹ç›®åˆ—è¡¨")
            if refresh_clicked:
                # å¼ºåˆ¶åˆ·æ–°é¡¹ç›®åˆ—è¡¨
                get_projects_from_disk.clear()
                st.rerun()
        
        # å¤„ç†åŠ è½½é€»è¾‘å¹¶æ˜¾ç¤ºæç¤º
        if load_clicked:
            if session_state.load_settings(selected_project):
                st.success(f"é¡¹ç›® '{selected_project}' å·²åŠ è½½")
                st.session_state['current_project'] = selected_project
            else:
                st.error(f"æœªæ‰¾åˆ°é¡¹ç›® '{selected_project}'")
                    
# æ˜¾ç¤ºå½“å‰é¡¹ç›® - æ›´ç´§å‡‘çš„å¸ƒå±€
        if 'current_project' in st.session_state and st.session_state['current_project']:
            current_project = st.session_state['current_project']
            
            # ä½¿ç”¨ä¸€è¡Œæ˜¾ç¤ºé¡¹ç›®åå’Œåˆ é™¤æŒ‰é’®
            project_row = st.container()
            
            with project_row:
                cols = st.columns([0.85, 0.15])
                
                with cols[0]:
                    # æ˜¾ç¤ºé¡¹ç›®åç§°
                    st.markdown(f"**å½“å‰é¡¹ç›®ï¼š** {current_project}")
                
                with cols[1]:
                    # æ·»åŠ åˆ é™¤æŒ‰é’®ï¼Œé»˜è®¤é€æ˜åº¦ä½
                    st.markdown("""
                    <style>
                    .delete-btn-wrapper button {
                        opacity: 0.2;
                        transition: opacity 0.3s ease;
                    }
                    .stButton:hover button {
                        opacity: 1 !important;
                    }
                    </style>
                    <div class="delete-btn-wrapper">
                    """, unsafe_allow_html=True)
                    delete_btn = st.button("âŒ", key="delete_project", help="åˆ é™¤è¯¥é¡¹ç›®")
                    st.markdown("</div>", unsafe_allow_html=True)
            
            if delete_btn:
                # è®¾ç½®åˆ é™¤ç¡®è®¤çŠ¶æ€
                st.session_state['show_delete_confirm'] = True
                st.rerun() # Rerun to show confirmation
            
            # æ˜¾ç¤ºåˆ é™¤ç¡®è®¤
            if st.session_state.get('show_delete_confirm', False):
                # ä½¿ç”¨æœ€ç›´æ¥çš„æ–¹å¼åˆ é™¤
                st.warning(f"ç¡®å®šè¦åˆ é™¤é¡¹ç›® '{current_project}' å—ï¼Ÿæ­¤æ“ä½œä¸å¯æ’¤é”€ã€‚")
                confirm_col1, confirm_col2 = st.columns(2)
                
                with confirm_col1:
                    if st.button("ç¡®è®¤åˆ é™¤", key="confirm_delete"):
                        # ç›´æ¥å¼ºåˆ¶åˆ é™¤
                        success = force_delete_project(current_project)
                        
                        if success:
                            # æ¸…ç†ä¼šè¯çŠ¶æ€
                            if 'current_project' in st.session_state:
                                deleted_project = st.session_state['current_project']
                                st.session_state.pop('current_project', None)
                                
                                # è®¾ç½®çŠ¶æ€æ ‡è®°åˆ é™¤æˆåŠŸ
                                st.session_state['show_delete_dialog'] = True
                                st.session_state['deleted_project_name'] = deleted_project
                                st.session_state.pop('show_delete_confirm', None)
                                # Clear cache after deleting project
                                get_projects_from_disk.clear()
                                st.rerun() # Rerun to update UI
                            else:
                                st.error(f"åˆ é™¤é¡¹ç›®å¤±è´¥ï¼Œè¯·æ£€æŸ¥æƒé™æˆ–æ‰‹åŠ¨åˆ é™¤æ–‡ä»¶")
                                st.session_state.pop('show_delete_confirm', None) # Hide confirm dialog on failure
                                st.rerun()
                
                with confirm_col2:
                    if st.button("å–æ¶ˆ", key="cancel_delete"):
                        # å–æ¶ˆåˆ é™¤æ“ä½œï¼Œé‡ç½®çŠ¶æ€
                        st.session_state.pop('show_delete_confirm', None)
                        st.rerun()
        
        # æ˜¾ç¤ºåˆ é™¤æˆåŠŸå¯¹è¯æ¡†
        if st.session_state.get('show_delete_dialog', False):
            deleted_name = st.session_state.get('deleted_project_name', '')
            
            # ä½¿ç”¨ä¸€ä¸ªæ™®é€šçš„Streamlitå®¹å™¨æ¥æ˜¾ç¤ºå¼¹çª—
            delete_dialog = st.container()
            with delete_dialog:
                # åˆ›å»ºä¸€ä¸ªç®€å•çš„å¡ç‰‡å¼å¯¹è¯æ¡†
                dialog_col1, dialog_col2, dialog_col3 = st.columns([1, 3, 1])
                
                with dialog_col2:
                    # æ˜¾ç¤ºæˆåŠŸæ¶ˆæ¯çš„å¡ç‰‡
                    with st.container():
                        st.success("âœ“ åˆ é™¤æˆåŠŸ")
                        st.markdown(f"### é¡¹ç›® \"{deleted_name}\" å·²æˆåŠŸåˆ é™¤ï¼")
                        
                        # æ·»åŠ é—´è·
                        st.write("")
                        
                        # çŸ¥é“äº†æŒ‰é’®
                        if st.button("çŸ¥é“äº†", key="ok_btn", use_container_width=True, type="primary"):
                            # å…³é—­å¯¹è¯æ¡†
                            st.session_state.pop('show_delete_dialog', None)
                            st.session_state.pop('deleted_project_name', None)
                            st.rerun()
        
        # ä½¿ç”¨ç©ºç™½è€Œä¸æ˜¯åˆ†å‰²çº¿
        st.write("")
        
        # åˆ›å»ºé¡¹ç›®éƒ¨åˆ† - æ›´ç´§å‡‘
        st.write("**åˆ›å»ºé¡¹ç›®**")
        create_col1, create_col2 = st.columns([3, 1])
        with create_col1:
            new_project = st.text_input(
                "åˆ›å»ºæ–°é¡¹ç›®",
                value="",
                placeholder="è¾“å…¥æ–°é¡¹ç›®åç§°",
                label_visibility="collapsed"
            )
        
        # å¸ƒå±€ï¼šæŒ‰é’®åœ¨å³
        with create_col2:
            save_clicked = st.button("ä¿å­˜", key="save_project")
        
        # å¤„ç†åˆ›å»ºé€»è¾‘å¹¶æ˜¾ç¤ºæç¤º
        if save_clicked:
            if new_project:
                if session_state.save_settings(new_project):
                    st.success(f"é¡¹ç›® '{new_project}' å·²åˆ›å»º")
                    st.session_state['current_project'] = new_project
                    # é‡æ–°åŠ è½½é¡µé¢ä»¥æ›´æ–°é¡¹ç›®åˆ—è¡¨
                    get_projects_from_disk.clear()
                    st.rerun()
            else:
                st.error("è¯·è¾“å…¥é¡¹ç›®åç§°")
        
        # åœ¨ä¾§è¾¹æ åº•éƒ¨æ˜¾ç¤ºç‰ˆæœ¬ä¿¡æ¯ï¼Œä½¿ç”¨ç©ºç™½å«åº•
        st.write("")
        st.write("")
        st.write("")
        st.write("")
        # ç‰ˆæœ¬ä¿¡æ¯ç§»åˆ°æœ€åº•éƒ¨
        st.caption("AIè§†é¢‘åˆ†æç³»ç»Ÿ v1.0.0")
    
    # ---- æ–°å¢ï¼šå¤„ç†é¡µé¢è·³è½¬è¯·æ±‚ ----
    if 'navigate_to_page' in st.session_state:
        target_page = st.session_state.pop('navigate_to_page') # è·å–å¹¶ç§»é™¤æ ‡å¿—
        # æ›´æ–°å¯¼èˆªèœå•çš„é€‰ä¸­çŠ¶æ€ï¼ˆå¦‚æœå¯èƒ½ä¸”éœ€è¦ï¼‰
        # è¿™é‡Œæˆ‘ä»¬ç›´æ¥è®¾ç½® page å˜é‡ï¼Œå› ä¸º st.radio çš„çŠ¶æ€ä¸å¥½ç›´æ¥ä¿®æ”¹
        if target_page in ["çƒ­è¯ç®¡ç†", "ç»´åº¦è®¾ç½®", "è§†é¢‘åˆ†æ", "ç»“æœç®¡ç†"]:
            page = target_page
        logger.info(f"Navigating to page: {page}")
    # ---- ç»“æŸæ–°å¢ ----

    # æ ¹æ®å¯¼èˆªåŠ è½½å¯¹åº”é¡µé¢
    if page == "çƒ­è¯ç®¡ç†":
        show_wordlist_page()
    elif page == "ç»´åº¦è®¾ç½®":
        show_dimension_page()
    elif page == "è§†é¢‘åˆ†æ":
        show_analysis_page()
    elif page == "ç»“æœç®¡ç†":
        show_results_page()

def show_wordlist_page():
    """æ˜¾ç¤ºçƒ­è¯ç®¡ç†é¡µé¢"""
    st.header("çƒ­è¯ç®¡ç†")
    st.markdown("åˆ›å»ºå’Œç®¡ç†ç”¨äºè¯­éŸ³è¯†åˆ«çš„çƒ­è¯åº“ï¼Œæé«˜å…³é”®è¯è¯†åˆ«å‡†ç¡®ç‡ã€‚")
    
    # ç¡®ä¿settingså­˜åœ¨
    if 'settings' not in st.session_state:
        st.session_state.settings = session_state.get_default_settings()
    
    # çƒ­è¯åˆ—è¡¨
    st.subheader("çƒ­è¯åˆ—è¡¨")
    
    # åˆå§‹åŒ–çƒ­è¯åˆ—è¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    if 'hot_words' not in st.session_state.settings:
        st.session_state.settings['hot_words'] = []
    
    # åˆ›å»ºçƒ­è¯æ•°æ®æ¡†
    if st.session_state.settings['hot_words']:
        hot_words_data = []
        for hw in st.session_state.settings['hot_words']:
            # ç§»é™¤ç±»åˆ«ä¿¡æ¯ï¼Œåªä¿ç•™åŸºæœ¬å­—æ®µ
            hot_words_data.append({
                'çƒ­è¯': hw.get('text', ''),
                'æƒé‡': hw.get('weight', 4),
                'è¯­è¨€': hw.get('lang', 'zh')
            })
        
        df = pd.DataFrame(hot_words_data)
    else:
        df = pd.DataFrame(columns=['çƒ­è¯', 'æƒé‡', 'è¯­è¨€'])
    
    # é˜²å¾¡æ€§æ£€æŸ¥ï¼šç¡®ä¿dfæ˜¯DataFrameè€Œä¸æ˜¯dict
    if not isinstance(df, pd.DataFrame):
        logger.warning(f"é¢„æœŸdfä¸ºDataFrameï¼Œå®é™…ä¸º{type(df)}")
        df = pd.DataFrame(df) if isinstance(df, dict) else pd.DataFrame()
    
    # é¡¶éƒ¨æ·»åŠ æ‰¹é‡æ“ä½œåŒºåŸŸ
    st.subheader("æ‰¹é‡æ“ä½œ", divider="gray")
    bulk_col1, bulk_col2, bulk_col3 = st.columns([1, 1, 1])
    
    with bulk_col1:
        default_weight = 4
        bulk_weight = st.number_input(
            "æ‰¹é‡è®¾ç½®æƒé‡", 
            min_value=1, 
            max_value=5, 
            value=default_weight,
            step=1,
            help="åŒæ—¶è®¾ç½®é€‰å®šçƒ­è¯çš„æƒé‡å€¼"
        )
    
    with bulk_col2:
        bulk_lang = st.selectbox(
            "æ‰¹é‡è®¾ç½®è¯­è¨€",
            options=["zh", "en"],
            index=0,
            help="åŒæ—¶è®¾ç½®é€‰å®šçƒ­è¯çš„è¯­è¨€(zh:ä¸­æ–‡, en:è‹±æ–‡)"
        )
    
    with bulk_col3:
        bulk_apply = st.button("åº”ç”¨åˆ°é€‰ä¸­è¡Œ", use_container_width=True)
        bulk_clear = st.button("æ¸…ç©ºæ‰€æœ‰", use_container_width=True)
    
    # å¦‚æœç‚¹å‡»æ¸…ç©ºæŒ‰é’®ï¼Œæç¤ºç¡®è®¤
    if bulk_clear:
        clear_confirm = st.warning("ç¡®å®šè¦æ¸…ç©ºæ‰€æœ‰çƒ­è¯å—ï¼Ÿæ­¤æ“ä½œä¸å¯æ’¤é”€ã€‚", icon="âš ï¸")
        clear_col1, clear_col2 = st.columns([1, 1])
        with clear_col1:
            if st.button("ç¡®è®¤æ¸…ç©º", type="primary", use_container_width=True):
                df = pd.DataFrame(columns=['çƒ­è¯', 'æƒé‡', 'è¯­è¨€'])
                st.success("å·²æ¸…ç©ºæ‰€æœ‰çƒ­è¯")
                st.rerun()
        with clear_col2:
            if st.button("å–æ¶ˆ", type="secondary", use_container_width=True):
                st.rerun()
    
    st.subheader("çƒ­è¯åˆ—è¡¨ç¼–è¾‘", divider="gray")
    
    # å¯ç¼–è¾‘è¡¨æ ¼ - å¢å¼ºç‰ˆæœ¬ï¼Œæ”¯æŒè¯­è¨€é€‰æ‹©
    edited_df = st.data_editor(
        df,
        num_rows="dynamic",
        column_config={
            "çƒ­è¯": st.column_config.TextColumn(
                "çƒ­è¯",
                width="large",
                help="æ¯ä¸ªè¯è¯­æœ€é•¿10ä¸ªæ±‰å­—æˆ–è‹±æ–‡å•è¯"
            ),
            "æƒé‡": st.column_config.NumberColumn(
                "æƒé‡", 
                min_value=1,
                max_value=5,
                step=1,
                format="%d",
                width="small",
                default=4,
                help="å–å€¼èŒƒå›´ä¸º[1, 5]ä¹‹é—´çš„æ•´æ•°ï¼Œå¸¸ç”¨å€¼ï¼š4"
            ),
            "è¯­è¨€": st.column_config.SelectboxColumn(
                "è¯­è¨€",
                width="small",
                options=["zh", "en"],
                default="zh",
                help="zh: ä¸­æ–‡, en: è‹±æ–‡"
            )
        },
        use_container_width=True,
        key="hot_words_editor",
        hide_index=True,
        height=400
    )
    
    # åº”ç”¨æ‰¹é‡æ“ä½œåˆ°é€‰ä¸­è¡Œ
    if bulk_apply and edited_df is not None and len(edited_df) > 0:
        selection = st.session_state.get("hot_words_editor_selected_rows", [])
        if selection:
            # è·å–é€‰ä¸­è¡Œçš„ç´¢å¼•
            selected_indices = [int(idx) for idx in selection]
            
            # åº”ç”¨æ‰¹é‡æ“ä½œ
            for idx in selected_indices:
                if idx < len(edited_df):
                    edited_df.at[idx, 'æƒé‡'] = bulk_weight
                    edited_df.at[idx, 'è¯­è¨€'] = bulk_lang
            
            st.success(f"å·²å°†æƒé‡ {bulk_weight} å’Œè¯­è¨€ {bulk_lang} åº”ç”¨åˆ° {len(selected_indices)} ä¸ªé€‰ä¸­çƒ­è¯")
    
    # æ˜¾ç¤ºé€‰æ‹©çš„è¡Œæ•°å’Œæ€»è¡Œæ•°ç»Ÿè®¡
    if edited_df is not None and len(edited_df) > 0:
        total_rows = len(edited_df)
        valid_rows = edited_df['çƒ­è¯'].notna().sum()
        st.caption(f"å…±æœ‰ {valid_rows} ä¸ªæœ‰æ•ˆçƒ­è¯ (æ€»è®¡ {total_rows} è¡Œ)")
    
    # å·²ç§»é™¤çƒ­è¯åˆ—è¡¨åç§°è¾“å…¥æ¡†ï¼Œæ‰€æœ‰çƒ­è¯ä»…é€šè¿‡é˜¿é‡Œäº‘APIç®¡ç†
    hotword_list_name = ""
    
    # æ·»åŠ ä¿å­˜æŒ‰é’®ï¼Œåªæœ‰åœ¨ç”¨æˆ·ç‚¹å‡»æ—¶æ‰å¤„ç†æ•°æ®
    # å·²ç¦ç”¨æœ¬åœ°"ä¿å­˜çƒ­è¯åˆ—è¡¨"æŒ‰é’®ï¼Œæ‰€æœ‰çƒ­è¯ä»…é€šè¿‡é˜¿é‡Œäº‘APIç®¡ç†
    
    # æ·»åŠ ä¸€äº›é—´è·
    st.write("")
    
    # ç›´æ¥æ·»åŠ åˆ›å»ºé˜¿é‡Œäº‘çƒ­è¯åˆ—è¡¨æŒ‰é’®
    create_hotwords_col1, create_hotwords_col2 = st.columns([1, 3])
    with create_hotwords_col1:
        create_cloud_btn = st.button("åˆ›å»ºé˜¿é‡Œäº‘çƒ­è¯åˆ—è¡¨", key="create_dashscope_vocab", type="primary", use_container_width=True)
    
    with create_hotwords_col2:
        # æ˜¾ç¤ºä¿¡æ¯æç¤º
        st.markdown("""
        <div style='background-color:#f8f9fa; padding:10px; border-radius:5px; font-size:0.9em;'>
            â„¹ï¸ <b>åˆ›å»ºé˜¿é‡Œäº‘çƒ­è¯åˆ—è¡¨</b> å°†å½“å‰çƒ­è¯æäº¤åˆ°é˜¿é‡Œäº‘è¯­éŸ³è¯†åˆ«æœåŠ¡ï¼Œæé«˜å…³é”®è¯è¯†åˆ«å‡†ç¡®ç‡ã€‚
            åˆ›å»ºæˆåŠŸåï¼Œè¯æ±‡è¡¨IDå°†è¢«è‡ªåŠ¨ä¿å­˜ï¼Œå¯ç”¨äºè¯­éŸ³è¯†åˆ«ã€‚
        </div>
        """, unsafe_allow_html=True)
    
    if create_cloud_btn:
        # å¼ºåˆ¶åŒæ­¥ç¼–è¾‘åçš„çƒ­è¯æ•°æ®
        new_hot_words = []
        if edited_df is not None and len(edited_df) > 0:
            for _, row in edited_df.iterrows():
                text = str(row.get('çƒ­è¯', '')).strip()
                if text and len(text) <= 10:
                    try:
                        weight = int(row.get('æƒé‡', 4))
                        weight = max(1, min(5, weight))
                    except:
                        weight = 4
                    lang = row.get('è¯­è¨€', 'zh')
                    if not lang or lang not in ['zh', 'en']:
                        lang = 'zh'
                    new_hot_words.append({'text': text, 'weight': weight, 'lang': lang})
        st.session_state.settings['hot_words'] = new_hot_words

        if not st.session_state.settings['hot_words']:
            st.error("è¯·å…ˆæ·»åŠ çƒ­è¯")
        else:
            # åˆ›å»ºè¿›åº¦æ¡å’ŒçŠ¶æ€å®¹å™¨
            progress_container = st.container()
            status_container = st.container()
            
            with progress_container:
                progress_bar = st.progress(0)
                status_text = st.empty()
            
            try:
                # ç¡®ä¿å‰ç¼€ä¸è¶…è¿‡10ä¸ªå­—ç¬¦ï¼ˆé˜¿é‡Œäº‘APIé™åˆ¶ï¼‰å¹¶ä¸”åªåŒ…å«è‹±æ–‡å­—æ¯å’Œæ•°å­—
                # å…ˆç§»é™¤éæ³•å­—ç¬¦
                prefix_name = re.sub(r'[^a-zA-Z0-9]', '', hotword_list_name)
                
                # å¦‚æœå‰ç¼€åç§°è¶…è¿‡6ä¸ªå­—ç¬¦ï¼Œå–å‰6ä¸ªå­—ç¬¦
                if len(prefix_name) > 6:
                    prefix_name = prefix_name[:6]
                
                # ä½¿ç”¨çŸ­æ—¶é—´æˆ³ï¼ˆæœ€å4ä½æ•°å­—ï¼‰ç”Ÿæˆå”¯ä¸€æ ‡è¯†
                time_suffix = str(int(time.time()))[-4:]
                auto_prefix = f"{prefix_name}{time_suffix}"
                
                # å¦‚æœå‰ç¼€ä»ç„¶è¶…è¿‡10ä¸ªå­—ç¬¦ï¼Œè¿›ä¸€æ­¥æˆªæ–­
                if len(auto_prefix) > 10:
                    auto_prefix = auto_prefix[:10]
                
                # ç¡®ä¿å‰ç¼€ä¸ä¸ºç©º
                if not auto_prefix:
                    auto_prefix = f"hw{time_suffix}"
                
                # é»˜è®¤ä½¿ç”¨æœ€å¸¸ç”¨çš„æ¨¡å‹
                default_model = "paraformer-v2"
                
                # æ›´æ–°è¿›åº¦æ¡
                status_text.text("æ­£åœ¨æ£€æŸ¥ç¯å¢ƒé…ç½®...")
                progress_bar.progress(10)
                
                # æ£€æŸ¥APIå¯†é’¥æ˜¯å¦è®¾ç½®
                api_key = os.getenv('DASHSCOPE_API_KEY', '')
                if not api_key:
                    with status_container:
                        st.error("ç¼ºå°‘DASHSCOPE_API_KEYç¯å¢ƒå˜é‡ï¼Œæ— æ³•åˆ›å»ºçƒ­è¯åˆ—è¡¨")
                        st.info("è¯·åœ¨.envæ–‡ä»¶ä¸­æ·»åŠ ä»¥ä¸‹å†…å®¹ï¼š\n```\nDASHSCOPE_API_KEY=æ‚¨çš„é˜¿é‡Œäº‘APIå¯†é’¥\n```")
                        # æ˜¾ç¤ºè®¾ç½®ç¯å¢ƒå˜é‡çš„å¸®åŠ©é“¾æ¥
                        st.markdown("[ç‚¹å‡»æ­¤å¤„äº†è§£å¦‚ä½•è·å–é˜¿é‡Œäº‘APIå¯†é’¥](https://help.aliyun.com/document_detail/175553.html)")
                    logger.error("ç¼ºå°‘DASHSCOPE_API_KEYç¯å¢ƒå˜é‡")
                    progress_bar.progress(100)
                    status_text.text("ç¯å¢ƒé…ç½®æ£€æŸ¥å¤±è´¥")
                    st.stop()
                
                # æ›´æ–°è¿›åº¦æ¡
                status_text.text("æ­£åœ¨å‡†å¤‡çƒ­è¯æ•°æ®...")
                progress_bar.progress(30)
                
                # å¯¹çƒ­è¯è¿›è¡Œæ ¼å¼åŒ–ï¼Œç¡®ä¿ç¬¦åˆé˜¿é‡Œäº‘APIè¦æ±‚
                formatted_hotwords = []
                for hw in st.session_state.settings['hot_words']:
                    # ç¡®ä¿ä¼ é€’æ­£ç¡®æ ¼å¼
                    formatted_hw = {
                        'text': hw['text'],
                        'weight': hw['weight'],
                        'lang': hw.get('lang', 'zh')
                    }
                    formatted_hotwords.append(formatted_hw)
                
                # è®°å½•APIè°ƒç”¨ä¿¡æ¯
                logger.info(f"å‡†å¤‡åˆ›å»ºé˜¿é‡Œäº‘çƒ­è¯åˆ—è¡¨ï¼Œå‰ç¼€:{auto_prefix}, æ¨¡å‹:{default_model}, çƒ­è¯æ•°é‡:{len(formatted_hotwords)}")
                
                # æ›´æ–°è¿›åº¦æ¡
                status_text.text("æ­£åœ¨æäº¤åˆ°é˜¿é‡Œäº‘...")
                progress_bar.progress(50)
                
                # ä½¿ç”¨æ ¼å¼åŒ–åçš„çƒ­è¯è°ƒç”¨API
                try:
                    # è°ƒç”¨å‰ç¡®è®¤çƒ­è¯æ•°é‡ä¸ä¸º0
                    if len(formatted_hotwords) == 0:
                        with status_container:
                            st.error("æ— æ³•åˆ›å»ºçƒ­è¯åˆ—è¡¨ï¼šçƒ­è¯æ•°é‡ä¸º0")
                            logger.error("çƒ­è¯æ•°é‡ä¸º0ï¼Œæ— æ³•åˆ›å»ºçƒ­è¯åˆ—è¡¨")
                            progress_bar.progress(100)
                            status_text.text("åˆ›å»ºå¤±è´¥")
                            st.stop()
                    
                    # æ£€æŸ¥å‰ç¼€é•¿åº¦
                    if len(auto_prefix) > 10:
                        old_prefix = auto_prefix
                        auto_prefix = auto_prefix[:10]
                        with status_container:
                            st.warning(f"å‰ç¼€ '{old_prefix}' è¶…è¿‡10ä¸ªå­—ç¬¦ï¼Œå·²è‡ªåŠ¨æˆªæ–­ä¸º '{auto_prefix}'")
                            logger.warning(f"å‰ç¼€è¿‡é•¿ï¼Œå·²æˆªæ–­: {old_prefix} -> {auto_prefix}")
                    
                    # æ£€æŸ¥çƒ­è¯æ–‡æœ¬é•¿åº¦ï¼Œè¿‡æ»¤æ‰è¶…é•¿çƒ­è¯
                    invalid_hotwords = [hw['text'] for hw in formatted_hotwords if len(hw['text']) > 10]
                    if invalid_hotwords:
                        # è¿‡æ»¤æ‰è¶…é•¿çƒ­è¯
                        valid_hotwords = [hw for hw in formatted_hotwords if len(hw['text']) <= 10]
                        formatted_hotwords = valid_hotwords
                        
                        with status_container:
                            st.warning(f"å·²è‡ªåŠ¨è¿‡æ»¤ {len(invalid_hotwords)} ä¸ªè¶…é•¿çƒ­è¯(æœ€å¤§10ä¸ªå­—ç¬¦): {', '.join(invalid_hotwords[:5])}" + 
                                    ("..." if len(invalid_hotwords) > 5 else ""))
                            logger.warning(f"å·²è¿‡æ»¤è¶…é•¿çƒ­è¯: {invalid_hotwords}")
                            
                        # å¦‚æœè¿‡æ»¤åæ²¡æœ‰åˆæ³•çƒ­è¯ï¼Œæ˜¾ç¤ºé”™è¯¯å¹¶åœæ­¢
                        if len(formatted_hotwords) == 0:
                            with status_container:
                                st.error("æ‰€æœ‰çƒ­è¯éƒ½è¶…å‡ºé•¿åº¦é™åˆ¶ï¼Œæ— æ³•åˆ›å»ºçƒ­è¯åˆ—è¡¨")
                                progress_bar.progress(100)
                                status_text.text("åˆ›å»ºå¤±è´¥")
                                st.stop()
                        else:
                            # æ˜¾ç¤ºè¿‡æ»¤åçš„åˆæ³•çƒ­è¯æ•°é‡
                            st.info(f"å°†ä½¿ç”¨ {len(formatted_hotwords)} ä¸ªåˆæ³•çƒ­è¯åˆ›å»ºçƒ­è¯åˆ—è¡¨")
                    
                    # æ·»åŠ ç½‘ç»œè¯·æ±‚è¶…æ—¶è®¾ç½®
                    result = create_vocabulary(auto_prefix, default_model, formatted_hotwords)
                    logger.info(f"APIå“åº”: {result}")
                    
                    # æ›´æ–°è¿›åº¦æ¡
                    progress_bar.progress(80)
                    
                    with status_container:
                        if 'output' in result:
                            if 'task_id' in result['output']:
                                task_id = result['output']['task_id']
                                message = f"è¯æ±‡è¡¨åˆ›å»ºä»»åŠ¡å·²æäº¤ï¼Œä»»åŠ¡ID: {task_id}"
                                logger.info(message)
                                
                                # æ›´æ–°è¿›åº¦æ¡
                                progress_bar.progress(100)
                                status_text.text("åˆ›å»ºä»»åŠ¡å·²æˆåŠŸæäº¤")
                                
                                # æ˜¾ç¤ºæˆåŠŸæ¶ˆæ¯
                                st.success(message)
                                st.info("è¯·åœ¨ã€Œè¯æ±‡è¡¨åˆ—è¡¨ã€æ ‡ç­¾ä¸­æŸ¥çœ‹ç»“æœï¼Œå¯èƒ½éœ€è¦ç­‰å¾…1-2åˆ†é’Ÿååˆ·æ–°åˆ—è¡¨")
                            
                            elif 'vocabulary_id' in result['output']:
                                vocabulary_id = result['output']['vocabulary_id']
                                message = f"è¯æ±‡è¡¨åˆ›å»ºæˆåŠŸï¼ŒID: {vocabulary_id}"
                                logger.info(message)
                                
                                # æ›´æ–°è¿›åº¦æ¡
                                progress_bar.progress(100)
                                status_text.text("åˆ›å»ºæˆåŠŸ")
                                
                                # æ˜¾ç¤ºæˆåŠŸæ¶ˆæ¯
                                st.success(message)
                                
                                # å°†æ–°åˆ›å»ºçš„è¯æ±‡è¡¨æ·»åŠ åˆ°ä¼šè¯çŠ¶æ€
                                if 'vocabulary_ids' not in st.session_state.settings:
                                    st.session_state.settings['vocabulary_ids'] = []
                                
                                # æå–å‰ç¼€
                                prefix = ''
                                if '-' in vocabulary_id:
                                    parts = vocabulary_id.split('-')
                                    if len(parts) > 1:
                                        prefix = parts[1]
                                
                                # æ·»åŠ åˆ°è¯æ±‡è¡¨åˆ—è¡¨
                                st.session_state.settings['vocabulary_ids'].append({
                                    'vocabulary_id': vocabulary_id,
                                    'prefix': prefix,
                                    'gmt_create': time.strftime("%Y-%m-%d %H:%M:%S"),
                                    'gmt_modified': time.strftime("%Y-%m-%d %H:%M:%S"),
                                    'status': 'OK',
                                    'target_model': default_model
                                })
                                
                                # æ˜¾ç¤ºåˆ›å»ºè¯¦æƒ…
                                st.json({
                                    "è¯æ±‡è¡¨ID": vocabulary_id,
                                    "å‰ç¼€": auto_prefix,
                                    "æ¨¡å‹": default_model,
                                    "çƒ­è¯æ•°é‡": len(formatted_hotwords),
                                    "åˆ›å»ºæ—¶é—´": time.strftime("%Y-%m-%d %H:%M:%S")
                                })
                                
                                st.info("çƒ­è¯åˆ—è¡¨å·²æ·»åŠ åˆ°è¯æ±‡è¡¨åˆ—è¡¨ä¸­ï¼Œå¯ä»¥åœ¨ã€Œè¯æ±‡è¡¨åˆ—è¡¨ã€æ ‡ç­¾æŸ¥çœ‹")
                            else:
                                error_code = result.get('code', 'UNKNOWN')
                                error_message = result.get('message', 'æœªçŸ¥é”™è¯¯')
                                
                                # æ›´æ–°è¿›åº¦æ¡
                                progress_bar.progress(100)
                                status_text.text("åˆ›å»ºå¤±è´¥")
                                
                                error_msg = f"åˆ›å»ºå¤±è´¥: {error_message}"
                                if error_code != 'UNKNOWN':
                                    error_msg += f" (é”™è¯¯ä»£ç : {error_code})"
                                
                                logger.error(error_msg)
                                st.error(error_msg)
                                
                                # æä¾›æ›´å…·ä½“çš„é”™è¯¯æŒ‡å¯¼å’Œè§£å†³æ–¹æ¡ˆ
                                if error_code == 'InvalidApiKey':
                                    st.error("APIå¯†é’¥æ— æ•ˆï¼Œè¯·æ£€æŸ¥DASHSCOPE_API_KEYç¯å¢ƒå˜é‡")
                                    st.info("è¯·åœ¨é˜¿é‡Œäº‘å®˜ç½‘è·å–æ­£ç¡®çš„APIå¯†é’¥ï¼Œå¹¶æ›´æ–°æ‚¨çš„ç¯å¢ƒå˜é‡")
                                elif error_code == 'QuotaExceeded':
                                    st.error("å·²è¶…å‡ºAPIé…é¢é™åˆ¶")
                                    st.info("è¯·å‰å¾€é˜¿é‡Œäº‘æ§åˆ¶å°æ£€æŸ¥æ‚¨çš„è´¦æˆ·ä½™é¢æˆ–æé«˜APIä½¿ç”¨é™é¢")
                                elif error_code == 'AccessDenied':
                                    st.error("æ²¡æœ‰è®¿é—®æƒé™")
                                    st.info("è¯·ç¡®è®¤æ‚¨çš„é˜¿é‡Œäº‘è´¦æˆ·å·²å¼€é€šDashScopeæœåŠ¡ï¼Œå¹¶å…·æœ‰ç›¸åº”çš„è®¿é—®æƒé™")
                                elif error_code == 'InvalidParameter':
                                    st.error(f"å‚æ•°é”™è¯¯: {error_message}")
                                    if "prefix should not be longer than 10 characters" in error_message:
                                        st.info("çƒ­è¯åˆ—è¡¨åç§°è¿‡é•¿ï¼Œåº”ä¿æŒåœ¨10ä¸ªå­—ç¬¦ä»¥å†…ã€‚è¯·ä½¿ç”¨æ›´çŸ­çš„å‰ç¼€é‡è¯•ã€‚")
                                    elif "prefix should be english letter and number" in error_message:
                                        st.info("çƒ­è¯åˆ—è¡¨å‰ç¼€åªèƒ½åŒ…å«è‹±æ–‡å­—æ¯å’Œæ•°å­—ã€‚å·²è‡ªåŠ¨ä¿®æ­£ï¼Œè¯·é‡è¯•ã€‚")
                                    elif "vocabulary is too large" in error_message:
                                        st.info("çƒ­è¯è¡¨è¿‡å¤§ï¼Œæ¯ä¸ªçƒ­è¯åˆ—è¡¨æœ€å¤šåŒ…å«500ä¸ªçƒ­è¯ï¼Œè¯·å‡å°‘çƒ­è¯æ•°é‡åé‡è¯•ã€‚")
                                    elif "text should not be longer than 10 characters" in error_message:
                                        st.info("å­˜åœ¨è¶…è¿‡10ä¸ªå­—ç¬¦çš„çƒ­è¯ï¼Œè¯·ç¡®ä¿æ¯ä¸ªçƒ­è¯ä¸è¶…è¿‡10ä¸ªå­—ç¬¦ã€‚")
                                    else:
                                        st.info("è¯·æ£€æŸ¥å‚æ•°æ˜¯å¦ç¬¦åˆé˜¿é‡Œäº‘APIè¦æ±‚ï¼Œè¯¦æƒ…å¯å‚è€ƒé˜¿é‡Œäº‘æ–‡æ¡£: https://help.aliyun.com/zh/model-studio/paraformer-recorded-speech-recognition-python-api")
                    
                    # æ£€æŸ¥çƒ­è¯æ–‡æœ¬é•¿åº¦ï¼Œè¿‡æ»¤æ‰è¶…é•¿çƒ­è¯
                    invalid_hotwords = [hw['text'] for hw in formatted_hotwords if len(hw['text']) > 10]
                    if invalid_hotwords:
                        # è¿‡æ»¤æ‰è¶…é•¿çƒ­è¯
                        valid_hotwords = [hw for hw in formatted_hotwords if len(hw['text']) <= 10]
                        formatted_hotwords = valid_hotwords
                        
                        with status_container:
                            st.warning(f"å·²è‡ªåŠ¨è¿‡æ»¤ {len(invalid_hotwords)} ä¸ªè¶…é•¿çƒ­è¯(æœ€å¤§10ä¸ªå­—ç¬¦): {', '.join(invalid_hotwords[:5])}" + 
                                    ("..." if len(invalid_hotwords) > 5 else ""))
                            logger.warning(f"å·²è¿‡æ»¤è¶…é•¿çƒ­è¯: {invalid_hotwords}")
                            
                        # å¦‚æœè¿‡æ»¤åæ²¡æœ‰åˆæ³•çƒ­è¯ï¼Œæ˜¾ç¤ºé”™è¯¯å¹¶åœæ­¢
                        if len(formatted_hotwords) == 0:
                            with status_container:
                                st.error("æ‰€æœ‰çƒ­è¯éƒ½è¶…å‡ºé•¿åº¦é™åˆ¶ï¼Œæ— æ³•åˆ›å»ºçƒ­è¯åˆ—è¡¨")
                                progress_bar.progress(100)
                                status_text.text("åˆ›å»ºå¤±è´¥")
                                st.stop()
                        else:
                            # æ˜¾ç¤ºè¿‡æ»¤åçš„åˆæ³•çƒ­è¯æ•°é‡
                            st.info(f"å°†ä½¿ç”¨ {len(formatted_hotwords)} ä¸ªåˆæ³•çƒ­è¯åˆ›å»ºçƒ­è¯åˆ—è¡¨")
                except Exception as api_err:
                    # æ›´æ–°è¿›åº¦æ¡
                    progress_bar.progress(100)
                    status_text.text("APIè°ƒç”¨å¤±è´¥")
                    
                    with status_container:
                        st.error(f"APIè°ƒç”¨å¤±è´¥: {str(api_err)}")
                        logger.error(f"åˆ›å»ºè¯æ±‡è¡¨APIè°ƒç”¨å¤±è´¥: {str(api_err)}")
                        st.info("è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒAPIå‚æ•°è®¾ç½®")
            except Exception as e:
                # æ›´æ–°è¿›åº¦æ¡
                progress_bar.progress(100)
                status_text.text("å¤„ç†å¤±è´¥")
                
                with status_container:
                    st.error(f"å¤„ç†å¤±è´¥: {str(e)}")
                    logger.error(f"åˆ›å»ºçƒ­è¯åˆ—è¡¨è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
    
    # æ‰¹é‡æ“ä½œ
    st.subheader("æ‰¹é‡æ“ä½œ")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        with st.expander("å¯¼å…¥çƒ­è¯"):
            upload_file = st.file_uploader(
                "ä¸Šä¼ CSVã€JSONæˆ–æ–‡æœ¬æ–‡ä»¶", 
                type=["csv", "txt", "json"],
                help="CSVæ ¼å¼ï¼šåŒ…å«'text'å’Œ'weight'åˆ—ã€‚JSONæ ¼å¼ï¼šç›´æ¥å¯¼å…¥ä¿å­˜çš„çƒ­è¯åˆ—è¡¨æ–‡ä»¶ã€‚æ–‡æœ¬æ ¼å¼ï¼šæ¯è¡Œä¸€ä¸ªçƒ­è¯ã€‚"
            )
            
            # æ£€æŸ¥å½“å‰æ˜¯å¦å·²æœ‰çƒ­è¯æ•°æ®
            has_existing_data = False
            if 'hot_words' in st.session_state.settings and st.session_state.settings['hot_words']:
                has_existing_data = True
                existing_count = len(st.session_state.settings['hot_words'])
                st.info(f"å½“å‰å·²æœ‰ {existing_count} ä¸ªçƒ­è¯ã€‚å¯¼å…¥æ–°çƒ­è¯ä¼šæ›¿æ¢ç°æœ‰çƒ­è¯ã€‚")
            
            if upload_file:
                col_import1, col_import2 = st.columns([1, 1])
                with col_import1:
                    import_clicked = st.button("å¯¼å…¥", key="btn_import_hotwords")
                
                if has_existing_data:
                    with col_import2:
                        append_mode = st.checkbox("è¿½åŠ æ¨¡å¼", value=False, help="å‹¾é€‰åå°†æ–°çƒ­è¯è¿½åŠ åˆ°ç°æœ‰çƒ­è¯åˆ—è¡¨ï¼Œè€Œä¸æ˜¯æ›¿æ¢")
                else:
                    append_mode = False

                
                if import_clicked:
                    # å¯¼å…¥hotword_utilsæ¨¡å—å¤„ç†çƒ­è¯å¯¼å…¥
                    from hotword_utils import import_hotwords_from_file
                    
                    # è°ƒç”¨æ¨¡å—åŒ–çš„å¯¼å…¥å‡½æ•°
                    imported_hotwords, list_name = import_hotwords_from_file(
                        upload_file, 
                        append_mode=append_mode, 
                        has_existing_data=has_existing_data
                    )
                    
                    # å¤„ç†å¯¼å…¥ç»“æœ
                    if imported_hotwords is not None:
                        # æ›¿æ¢æˆ–è¿½åŠ çƒ­è¯
                        if not append_mode or not has_existing_data:
                            # æ›¿æ¢æ¨¡å¼
                            st.session_state.settings['hot_words'] = imported_hotwords
                        
                        # è®¾ç½®çƒ­è¯åˆ—è¡¨åç§°
                        if list_name:
                            st.session_state.settings['hot_words_name'] = list_name
                        
                        # ä¿å­˜å½“å‰è®¾ç½®ï¼Œç¡®ä¿çƒ­è¯åˆ—è¡¨è¢«æŒä¹…åŒ–
                        try:
                            current_project = st.session_state.get('current_project', 'default')
                            if current_project is None:
                                current_project = 'default'
                            session_state.save_settings(current_project)
                            
                            # è§¦å‘é¡µé¢é‡æ–°åŠ è½½ä»¥æ˜¾ç¤ºå¯¼å…¥çš„çƒ­è¯
                            st.rerun()
                        except Exception as save_err:
                            st.error(f"ä¿å­˜è®¾ç½®å¤±è´¥: {str(save_err)}")
                            logger.error(f"ä¿å­˜çƒ­è¯è®¾ç½®å¤±è´¥: {str(save_err)}")
    
    with col2:
        with st.expander("å¯¼å‡ºçƒ­è¯"):
            export_format = st.radio(
                "å¯¼å‡ºæ ¼å¼",
                options=["CSV", "TXT"],
                horizontal=True
            )
            
            if st.button("å¯¼å‡º"):
                if st.session_state.settings['hot_words']:
                    if export_format == "CSV":
                        # ç¡®ä¿å¯¼å‡ºçƒ­è¯æ—¶åŒ…å«ç±»åˆ«ä¿¡æ¯
                        export_data = []
                        for hw in st.session_state.settings['hot_words']:
                            export_item = {
                                'text': hw['text'],
                                'weight': hw['weight'],
                                'lang': hw.get('lang', 'zh')
                            }
                            export_data.append(export_item)
                            
                        df_export = pd.DataFrame(export_data)
                        csv = df_export.to_csv(index=False)
                        st.download_button(
                            "ä¸‹è½½CSV",
                            csv,
                            "hotwords.csv",
                            "text/csv",
                            key="download_csv"
                        )
                    else:  # TXT
                        text = "\n".join([hw['text'] for hw in st.session_state.settings['hot_words']])
                        st.download_button(
                            "ä¸‹è½½TXT",
                            text,
                            "hotwords.txt",
                            "text/plain",
                            key="download_txt"
                        )
                else:
                    st.warning("æ²¡æœ‰çƒ­è¯å¯å¯¼å‡º")
    
    with col3:
        with st.expander("æ‰¹é‡æƒé‡è®¾ç½®"):
            # é€‰æ‹©è¯­è¨€
            lang = st.selectbox(
                "é€‰æ‹©è¯­è¨€",
                ["zh", "en"],
                index=0,
                help="é€‰æ‹©è¦è®¾ç½®æƒé‡çš„çƒ­è¯è¯­è¨€"
            )
            
            # æƒé‡è®¾ç½®
            weight = st.slider(
                "è®¾ç½®æƒé‡",
                min_value=1,
                max_value=5,
                value=4,
                step=1,
                help="å–å€¼èŒƒå›´ä¸º[1, 5]ä¹‹é—´çš„æ•´æ•°ï¼Œå¸¸ç”¨å€¼ï¼š4"
            )
            
            if st.button("åº”ç”¨"):
                if st.session_state.settings['hot_words']:
                    count = 0
                    for hw in st.session_state.settings['hot_words']:
                        if hw.get('lang') == lang:
                            hw['weight'] = int(weight)
                            count += 1
                    
                    if count > 0:
                        st.success(f"å·²æ›´æ–° {count} ä¸ªçƒ­è¯çš„æƒé‡")
                    else:
                        st.info(f"æ²¡æœ‰æ‰¾åˆ°{lang}è¯­è¨€çš„çƒ­è¯")
                else:
                    st.warning("æ²¡æœ‰çƒ­è¯å¯è®¾ç½®")

    # æ·»åŠ çƒ­è¯è¯æ±‡è¡¨ç®¡ç†åŠŸèƒ½
    st.subheader("è¯æ±‡è¡¨ç®¡ç†")
    
    # åˆå§‹åŒ–è¯æ±‡è¡¨åˆ—è¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    if 'vocabulary_ids' not in st.session_state.settings:
        st.session_state.settings['vocabulary_ids'] = []
    
    # è‡ªåŠ¨ä»é˜¿é‡Œäº‘è·å–è¯æ±‡è¡¨åˆ—è¡¨
    auto_refresh_placeholder = st.empty()
    
    try:
        with auto_refresh_placeholder.container():
            with st.spinner("æ­£åœ¨ä»é˜¿é‡Œäº‘è·å–è¯æ±‡è¡¨åˆ—è¡¨..."):
                # æ£€æŸ¥APIå¯†é’¥æ˜¯å¦è®¾ç½®
                api_key = os.getenv('DASHSCOPE_API_KEY', 'sk-fb02b49dcf5445ebada6d4ba70b1f8f1') # Fallback to hardcoded key if needed
                if not api_key:
                    st.error("ç¼ºå°‘DASHSCOPE_API_KEYç¯å¢ƒå˜é‡ï¼Œæ— æ³•è·å–è¯æ±‡è¡¨åˆ—è¡¨")
                    st.info("è¯·åœ¨ç¯å¢ƒå˜é‡æˆ–.envæ–‡ä»¶ä¸­è®¾ç½®DASHSCOPE_API_KEY")
                    logger.error("ç¼ºå°‘DASHSCOPE_API_KEYç¯å¢ƒå˜é‡")
                    # Directly stop execution within the spinner context might be problematic
                    # Instead, set a flag or return early
                    vocab_list = {"error": "Missing API Key"}
                else:
                    # è°ƒç”¨APIè·å–è¯æ±‡è¡¨åˆ—è¡¨
                    vocab_list = list_vocabulary()
        
        # Process the result outside the spinner context
        if isinstance(vocab_list, dict) and 'error' in vocab_list:
             # Handle errors like missing API key gracefully
             pass # Error already displayed
        elif 'output' in vocab_list and 'vocabulary_list' in vocab_list['output']:
            # æ¸…ç©ºç°æœ‰åˆ—è¡¨
            st.session_state.settings['vocabulary_ids'] = []
            
            # æ·»åŠ æ–°æ•°æ®
            for vocab in vocab_list['output']['vocabulary_list']:
                # æå–å‰ç¼€éƒ¨åˆ†
                vocab_id = vocab.get('vocabulary_id', '')
                prefix = ''
                if '-' in vocab_id:
                    parts = vocab_id.split('-')
                    if len(parts) > 1:
                        prefix = parts[1]
                
                # æ·»åŠ åˆ°è¯æ±‡è¡¨åˆ—è¡¨
                st.session_state.settings['vocabulary_ids'].append({
                    'vocabulary_id': vocab_id,
                    'prefix': prefix,
                    'gmt_create': vocab.get('gmt_create', ''),
                    'gmt_modified': vocab.get('gmt_modified', ''),
                    'status': vocab.get('status', ''),
                    'target_model': vocab.get('target_model', 'æœªçŸ¥')
                })
            
            total_count = len(vocab_list['output']['vocabulary_list'])
            success_count = sum(1 for v in vocab_list['output']['vocabulary_list'] if v.get('status') == 'OK')
            
            # Display success message only if successful
            # st.success(f"å·²ä»é˜¿é‡Œäº‘è·å– {total_count} ä¸ªè¯æ±‡è¡¨ï¼ˆå…¶ä¸­ {success_count} ä¸ªçŠ¶æ€æ­£å¸¸ï¼‰")
            
            # å¦‚æœæœ‰åˆ›å»ºä¸­çš„è¯æ±‡è¡¨ï¼Œæä¾›æç¤º
            creating_count = sum(1 for v in vocab_list['output']['vocabulary_list'] if v.get('status') == 'CREATING')
            if creating_count > 0:
                st.info(f"æœ‰ {creating_count} ä¸ªè¯æ±‡è¡¨æ­£åœ¨åˆ›å»ºä¸­")
            
            # å¦‚æœæœ‰å¤±è´¥çš„è¯æ±‡è¡¨ï¼Œæä¾›æç¤º
            failed_count = sum(1 for v in vocab_list['output']['vocabulary_list'] if v.get('status') == 'FAILED')
            if failed_count > 0:
                st.warning(f"æœ‰ {failed_count} ä¸ªè¯æ±‡è¡¨åˆ›å»ºå¤±è´¥ï¼Œè¯·æ£€æŸ¥å‚æ•°åé‡è¯•")
            
        else:
            # Handle API call failures (including ConnectionError)
            error_code = vocab_list.get('code', 'UNKNOWN')
            error_message = vocab_list.get('message', 'æœªçŸ¥é”™è¯¯')
            
            error_msg = f"è·å–é˜¿é‡Œäº‘è¯æ±‡è¡¨å¤±è´¥: {error_message}"
            if error_code != 'UNKNOWN':
                error_msg += f" (é”™è¯¯ä»£ç : {error_code})"
            
            logger.error(error_msg)
            # Display error prominently in the UI
            st.error(error_msg)
            
            # æä¾›æ›´å…·ä½“çš„é”™è¯¯æŒ‡å¯¼
            if error_code == 'InvalidApiKey':
                st.info("APIå¯†é’¥æ— æ•ˆï¼Œè¯·æ£€æŸ¥DASHSCOPE_API_KEYç¯å¢ƒå˜é‡")
            elif error_code == 'QuotaExceeded':
                st.info("å·²è¶…å‡ºAPIé…é¢é™åˆ¶ï¼Œè¯·è”ç³»é˜¿é‡Œäº‘å®¢æœ")
            elif error_code == 'AccessDenied':
                st.info("æ²¡æœ‰è®¿é—®æƒé™ï¼Œè¯·ç¡®è®¤è´¦æˆ·æ˜¯å¦å¼€é€šäº†ç›¸å…³æœåŠ¡")
            elif error_code == 'ConnectionError':
                st.info("æ— æ³•è¿æ¥åˆ°é˜¿é‡Œäº‘æœåŠ¡ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥ã€é˜²ç«å¢™æˆ–ä»£ç†è®¾ç½®ã€‚")
            elif error_code == 'TimeoutError':
                st.info("è¯·æ±‚è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•æˆ–æ£€æŸ¥ç½‘ç»œçŠ¶å†µã€‚")

    except Exception as e:
        logger.error(f"åˆ·æ–°è¯æ±‡è¡¨åˆ—è¡¨å¤±è´¥: {str(e)}", exc_info=True)
        # Display general error in UI
        st.error(f"å¤„ç†è¯æ±‡è¡¨åˆ—è¡¨æ—¶å‡ºé”™: {str(e)}")
    
    # æ¸…ç©ºå ä½ç¬¦å†…å®¹ï¼Œä¿æŒç•Œé¢æ•´æ´
    auto_refresh_placeholder.empty()
    
    # å±•ç¤ºè¯æ±‡è¡¨åˆ—è¡¨
    st.subheader("è¯æ±‡è¡¨åˆ—è¡¨")
    
    if not st.session_state.settings['vocabulary_ids']:
        st.info('å°šæœªåˆ›å»ºä»»ä½•è¯æ±‡è¡¨ã€‚æ‚¨å¯ä»¥ä½¿ç”¨"æ·»åŠ çƒ­è¯"åŠŸèƒ½æ·»åŠ çƒ­è¯åï¼Œé€šè¿‡"åˆ›å»ºé˜¿é‡Œäº‘çƒ­è¯åˆ—è¡¨"æŒ‰é’®åˆ›å»ºè¯æ±‡è¡¨ã€‚')
    else:
        # æ˜¾ç¤ºè¯æ±‡è¡¨åˆ—è¡¨
        vocab_data = []
        for vocab in st.session_state.settings['vocabulary_ids']:
            # å¤„ç†æ—¶é—´æ˜¾ç¤ºæ ¼å¼
            create_time = vocab.get('gmt_create', '')
            if create_time:
                try:
                    # å°è¯•è½¬æ¢æ—¶é—´æˆ³ä¸ºå¯è¯»æ ¼å¼
                    create_time_float = float(create_time) / 1000  # å‡è®¾æ—¶é—´æˆ³æ˜¯æ¯«ç§’æ ¼å¼
                    create_time = datetime.fromtimestamp(create_time_float).strftime('%Y-%m-%d %H:%M:%S')
                except:
                    pass  # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œä¿æŒåŸæ ·
            
            # ç”ŸæˆçŠ¶æ€æ ‡ç­¾
            status = vocab.get('status', '')
            if status == 'OK':
                status_display = "âœ… æ­£å¸¸"
            elif status == 'CREATING':
                status_display = "â±ï¸ åˆ›å»ºä¸­"
            elif status == 'FAILED':
                status_display = "âŒ å¤±è´¥"
            else:
                status_display = f"âš ï¸ {status}"
            
            vocab_data.append({
                "ID": vocab.get('vocabulary_id', ''),
                "åç§°": vocab.get('prefix', ''),
                "æ¨¡å‹": vocab.get('target_model', 'æœªçŸ¥'),
                "åˆ›å»ºæ—¶é—´": create_time,
                "çŠ¶æ€": status_display
            })
        
        # åˆ›å»ºä¸€ä¸ªå¯æœç´¢å’Œæ’åºçš„DataFrame
        vocab_df = pd.DataFrame(vocab_data)
        
        # æ·»åŠ æœç´¢æ¡†
        search_term = st.text_input("æœç´¢è¯æ±‡è¡¨", placeholder="è¾“å…¥IDæˆ–åç§°æœç´¢", key="vocab_search")
        if search_term:
            # è¿‡æ»¤DataFrame
            vocab_df = vocab_df[
                vocab_df['ID'].str.contains(search_term, case=False, na=False) | 
                vocab_df['åç§°'].str.contains(search_term, case=False, na=False)
            ]
        
        # æ˜¾ç¤ºå¸¦æœ‰æ ·å¼çš„DataFrame
        # st.dataframe(
        #     vocab_df,
        #     use_container_width=True,
        #     height=300
        # )
        
        # ä½¿ç”¨è‡ªå®šä¹‰è¡¨æ ¼å±•ç¤ºï¼Œä»¥ä¾¿æ¯è¡Œæ·»åŠ åˆ é™¤æŒ‰é’®
        st.markdown("##### è¯æ±‡è¡¨åˆ—è¡¨")
        
        # åˆ›å»ºè¡¨å¤´
        cols = st.columns([3, 2, 2, 3, 2, 1, 1])
        headers = ["ID", "åç§°", "æ¨¡å‹", "åˆ›å»ºæ—¶é—´", "çŠ¶æ€", "æ“ä½œ", "æŸ¥è¯¢"]
        for col, header in zip(cols, headers):
            col.markdown(f"**{header}**")
        
        st.markdown("---")  # è¡¨å¤´ä¸å†…å®¹åˆ†éš”çº¿
        
        # ç”¨äºå­˜å‚¨è¢«åˆ é™¤çš„è¯æ±‡è¡¨ID
        if 'deleted_vocab_ids' not in st.session_state:
            st.session_state.deleted_vocab_ids = []
            
        # ç”¨äºå­˜å‚¨å·²å±•å¼€æŸ¥è¯¢è¯¦æƒ…çš„è¯æ±‡è¡¨ID
        if 'expanded_vocab_ids' not in st.session_state:
            st.session_state.expanded_vocab_ids = []
        
        # ä¸ºæ¯è¡Œæ˜¾ç¤ºæ•°æ®å’Œæ“ä½œæŒ‰é’®
        for i, row in vocab_df.iterrows():
            vocab_id = row["ID"]
            
            # å¦‚æœè¯¥IDå·²è¢«åˆ é™¤ï¼Œåˆ™è·³è¿‡
            if vocab_id in st.session_state.deleted_vocab_ids:
                continue
                
            row_cols = st.columns([3, 2, 2, 3, 2, 1, 1])
            row_cols[0].text(row["ID"])
            row_cols[1].text(row["åç§°"])
            row_cols[2].text(row["æ¨¡å‹"])
            row_cols[3].text(row["åˆ›å»ºæ—¶é—´"])
            row_cols[4].markdown(row["çŠ¶æ€"])
            
            # åˆ é™¤æŒ‰é’®
            if row_cols[5].button("åˆ é™¤", key=f"delete_btn_{vocab_id}", use_container_width=True):
                try:
                    with st.spinner(f"æ­£åœ¨åˆ é™¤è¯æ±‡è¡¨ {vocab_id}..."):
                        result = delete_vocabulary(vocab_id)
                    
                    if 'output' in result:
                        # ä»ä¼šè¯çŠ¶æ€ä¸­ç§»é™¤
                        st.session_state.settings['vocabulary_ids'] = [
                            v for v in st.session_state.settings['vocabulary_ids'] 
                            if v.get('vocabulary_id') != vocab_id
                        ]
                        
                        # æ·»åŠ åˆ°å·²åˆ é™¤åˆ—è¡¨
                        st.session_state.deleted_vocab_ids.append(vocab_id)
                        
                        # æ˜¾ç¤ºæˆåŠŸæ¶ˆæ¯
                        st.success(f"å·²æˆåŠŸåˆ é™¤è¯æ±‡è¡¨ {vocab_id}")
                        time.sleep(1)  # æ˜¾ç¤ºä¿¡æ¯åçŸ­æš‚å»¶è¿Ÿ
                        st.rerun()  # é‡æ–°åŠ è½½é¡µé¢æ›´æ–°åˆ—è¡¨
                    else:
                        error_code = result.get('code', 'UNKNOWN')
                        error_message = result.get('message', 'æœªçŸ¥é”™è¯¯')
                        
                        st.error(f"åˆ é™¤å¤±è´¥: {error_message}")
                        if error_code != 'UNKNOWN':
                            st.error(f"é”™è¯¯ä»£ç : {error_code}")
                            
                        # æä¾›é”™è¯¯å¤„ç†å»ºè®®
                        if error_code == 'ResourceNotFound':
                            st.warning("æ‰¾ä¸åˆ°æŒ‡å®šçš„è¯æ±‡è¡¨ï¼Œå¯èƒ½å·²è¢«åˆ é™¤")
                            # ä»ä¼šè¯çŠ¶æ€ä¸­ç§»é™¤
                            st.session_state.settings['vocabulary_ids'] = [
                                v for v in st.session_state.settings['vocabulary_ids'] 
                                if v.get('vocabulary_id') != vocab_id
                            ]
                            # æ·»åŠ åˆ°å·²åˆ é™¤åˆ—è¡¨
                            st.session_state.deleted_vocab_ids.append(vocab_id)
                            st.info("å·²ä»æœ¬åœ°åˆ—è¡¨ç§»é™¤")
                            time.sleep(1)
                            st.rerun()  # é‡æ–°åŠ è½½é¡µé¢æ›´æ–°åˆ—è¡¨
                except Exception as e:
                    st.error(f"åˆ é™¤å¤±è´¥: {str(e)}")
                    with st.expander("æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯"):
                        import traceback
                        st.code(traceback.format_exc(), language="python")
            
            # æŸ¥è¯¢æŒ‰é’®
            if row_cols[6].button("æŸ¥è¯¢", key=f"query_btn_{vocab_id}", use_container_width=True):
                # åˆ‡æ¢å±•å¼€/æŠ˜å çŠ¶æ€
                if vocab_id in st.session_state.expanded_vocab_ids:
                    st.session_state.expanded_vocab_ids.remove(vocab_id)
                else:
                    st.session_state.expanded_vocab_ids.append(vocab_id)
                    
            # å¦‚æœè¯¥è¯æ±‡è¡¨è¯¦æƒ…å·²å±•å¼€ï¼Œæ˜¾ç¤ºè¯¦æƒ…
            if vocab_id in st.session_state.expanded_vocab_ids:
                with st.container():
                    st.markdown("---")  # è¯¦æƒ…ä¸è¡Œçš„åˆ†éš”çº¿
                    
                    # åˆ›å»ºå›ºå®šå®½åº¦çš„è¯¦æƒ…åŒº
                    detail_col = st.container()
                    with detail_col:
                        try:
                            with st.spinner(f"æ­£åœ¨æŸ¥è¯¢è¯æ±‡è¡¨ {vocab_id} çš„è¯¦æƒ…..."):
                                result = query_vocabulary(vocab_id)
                            
                            if 'output' in result:
                                # æ˜¾ç¤ºè¯æ±‡è¡¨è¯¦æƒ…çš„å…³é”®ä¿¡æ¯
                                vocab_details = result['output']
                                
                                # åˆ›å»ºä¸€ä¸ªæ ¼å¼åŒ–çš„è¯¦æƒ…å¡ç‰‡
                                st.markdown(f"""
                                <div style="background-color:#f0f2f6;padding:10px;border-radius:5px;margin-bottom:10px;">
                                    <h5 style="color:#0068c9;">è¯æ±‡è¡¨ {row["åç§°"]} è¯¦æƒ…</h5>
                                </div>
                                """, unsafe_allow_html=True)
                                
                                if 'vocabulary' in vocab_details:
                                    hot_words = vocab_details['vocabulary']
                                    
                                    # æœ‰çƒ­è¯æ•°æ®æ—¶æ˜¾ç¤ºçƒ­è¯è¡¨æ ¼
                                    if hot_words:
                                        # é™åˆ¶å±•ç¤ºçš„çƒ­è¯æ•°é‡
                                        display_words = hot_words[:10]  # åªå±•ç¤ºå‰10ä¸ª
                                        
                                        # åˆ›å»ºçƒ­è¯é¢„è§ˆè¡¨æ ¼
                                        hot_words_preview = []
                                        for hw in display_words:
                                            hot_words_preview.append({
                                                "çƒ­è¯": hw.get('text', ''),
                                                "æƒé‡": hw.get('weight', 4),
                                                "è¯­è¨€": hw.get('lang', 'zh')
                                            })
                                        
                                        hot_words_count = len(hot_words)
                                        display_count = len(display_words)
                                        
                                        # æ˜¾ç¤ºçƒ­è¯ä¿¡æ¯
                                        st.markdown(f"<p style='color:#555;'>åŒ…å« <b>{hot_words_count}</b> ä¸ªçƒ­è¯ï¼Œæ˜¾ç¤ºå‰ {display_count} ä¸ªï¼š</p>", unsafe_allow_html=True)
                                        
                                        # æ˜¾ç¤ºçƒ­è¯è¡¨æ ¼
                                        st.dataframe(
                                            pd.DataFrame(hot_words_preview),
                                            use_container_width=True,
                                            height=min(200, 50 + 35 * len(display_words))  # åŠ¨æ€è°ƒæ•´é«˜åº¦
                                        )
                                        
                                        # æä¾›å¯¼å‡ºåŠŸèƒ½
                                        export_json = json.dumps([
                                            {"text": hw.get('text', ''), "weight": hw.get('weight', 4), "lang": hw.get('lang', 'zh')}
                                            for hw in hot_words
                                        ], ensure_ascii=False, indent=2)
                                        
                                        download_col1, download_col2 = st.columns([1, 5])
                                        with download_col1:
                                            st.download_button(
                                                "å¯¼å‡ºçƒ­è¯",
                                                export_json,
                                                f"{vocab_id}_hotwords.json",
                                                "application/json",
                                                key=f"download_hw_{vocab_id}"
                                            )
                                        
                                        with download_col2:
                                            if hot_words_count > display_count:
                                                st.caption(f"* å¯¼å‡ºçš„æ–‡ä»¶åŒ…å«å…¨éƒ¨ {hot_words_count} ä¸ªçƒ­è¯")
                                    else:
                                        st.warning("è¯¥è¯æ±‡è¡¨ä¸åŒ…å«ä»»ä½•çƒ­è¯")
                                
                                # æ·»åŠ æŸ¥çœ‹åŸå§‹JSONçš„å±•å¼€é€‰é¡¹
                                with st.expander("æŸ¥çœ‹APIå“åº”è¯¦æƒ…"):
                                    st.json(vocab_details)
                            else:
                                error_code = result.get('code', 'UNKNOWN')
                                error_message = result.get('message', 'æœªçŸ¥é”™è¯¯')
                                
                                st.error(f"æŸ¥è¯¢å¤±è´¥: {error_message}")
                                if error_code != 'UNKNOWN':
                                    st.error(f"é”™è¯¯ä»£ç : {error_code}")
                                    
                                # æä¾›é”™è¯¯å¤„ç†å»ºè®®
                                if error_code == 'ResourceNotFound':
                                    st.warning("æ‰¾ä¸åˆ°æŒ‡å®šçš„è¯æ±‡è¡¨ï¼Œå¯èƒ½å·²è¢«åˆ é™¤")
                                    st.info("è¯·åˆ·æ–°é¡µé¢ä»¥è·å–æœ€æ–°çŠ¶æ€")
                                    # ä»å±•å¼€åˆ—è¡¨ä¸­ç§»é™¤
                                    if vocab_id in st.session_state.expanded_vocab_ids:
                                        st.session_state.expanded_vocab_ids.remove(vocab_id)
                        except Exception as e:
                            st.error(f"æŸ¥è¯¢å¤±è´¥: {str(e)}")
                            with st.expander("æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯"):
                                import traceback
                                st.code(traceback.format_exc(), language="python")
                    
                    st.markdown("---")  # è¯¦æƒ…åŒºçš„ç»“æŸåˆ†éš”çº¿
            
            # è¡Œåˆ†éš”çº¿
            st.markdown("---")
        
        # æä¾›æ€»è®¡ä¿¡æ¯
        st.caption(f"å…±æ‰¾åˆ° {len(vocab_df) - len(st.session_state.deleted_vocab_ids)} ä¸ªè¯æ±‡è¡¨")

def show_dimension_page():
    """æ˜¾ç¤ºç»´åº¦è®¾ç½®é¡µé¢"""
    st.title("ç»´åº¦è®¾ç½®")
    
    st.write("å®šä¹‰å†…å®¹åˆ†æçš„ä¸»é¢˜ç»´åº¦å’Œå±‚çº§ç»“æ„ï¼Œæ„å»ºä¸ªæ€§åŒ–çš„å†…å®¹ç­›é€‰ä½“ç³»ã€‚")
    
    # ç¡®ä¿settingså­˜åœ¨
    if 'settings' not in st.session_state:
        st.session_state.settings = session_state.get_default_settings()
    
    # åˆå§‹åŒ–æ¨¡æ¿è·Ÿè¸ªçŠ¶æ€ï¼ˆè¿½è¸ªå½“å‰åŠ è½½çš„æ¨¡æ¿åç§°å’Œæ˜¯å¦æœ‰ä¿®æ”¹ï¼‰
    if 'current_template' not in st.session_state:
        st.session_state.current_template = None
    if 'has_dimension_changes' not in st.session_state:
        st.session_state.has_dimension_changes = False
    
    # å¦‚æœtemplatesä¸å­˜åœ¨ï¼Œåˆ™åˆå§‹åŒ–
    if 'templates' not in st.session_state:
        st.session_state.templates = {}
        logger.info("åˆå§‹åŒ–templateså­—å…¸")
    
    # åˆå§‹åŒ–ç»´åº¦ç¼–è¾‘å™¨
    current_dimensions = st.session_state.get('settings', {}).get('dimensions', None)
    
    # ç¡®ä¿åœ¨é¡¹ç›®åŠ è½½çš„åˆå§‹é˜¶æ®µåŠ è½½core_templates.jsonæ–‡ä»¶
    if 'core_templates_loaded' not in st.session_state:
        try:
            logger.info("å¼€å§‹åˆå§‹åŒ–åŠ è½½core_templates.json")
            # å°è¯•åŠ è½½core_templates.jsonæ–‡ä»¶
            core_template_path = os.path.join('data', 'dimensions', 'core_templates.json')
            if os.path.exists(core_template_path):
                with open(core_template_path, 'r', encoding='utf-8') as f:
                    core_templates = json.load(f)
                logger.info(f"core_templates.jsonå†…å®¹: {core_templates}")
                
                # å°†core_templatesæ·»åŠ åˆ°session_state.templates
                # ä½¿ç”¨æ­£ç¡®çš„é”®åï¼Œç¡®ä¿ä¸ä¸‹æ‹‰åˆ—è¡¨ä¸€è‡´
                st.session_state.templates['@core_templates.json'] = core_templates
                logger.info(f"å·²æ·»åŠ æ¨¡æ¿åˆ°session_state.templatesï¼Œé”®ä¸º@core_templates.json")
                
                # è‡ªåŠ¨åº”ç”¨åˆ°å½“å‰é¡¹ç›®ï¼ˆå¦‚æœå°šæœªè®¾ç½®ç»´åº¦ï¼‰
                if not current_dimensions:
                    logger.info("å½“å‰æ²¡æœ‰ç»´åº¦è®¾ç½®ï¼Œåº”ç”¨core_templatesä½œä¸ºé»˜è®¤ç»´åº¦")
                    # è®¾ç½®ç»´åº¦æ•°æ® - ä½¿ç”¨æ–°çš„ç»“æ„
                    initial_dimensions = {
                        'title': 'å“ç‰Œè®¤çŸ¥',
                        'level1': list(core_templates.keys()),
                        'level2': core_templates
                    }
                    
                    # ç”Ÿæˆæƒé‡è®¾ç½® - æ”¯æŒå¤šçº§ç»´åº¦
                    weights = {
                        'title': 1.0,
                        'level1': {},
                        'level2': {}
                    }
                    
                    # ä¸ºä¸€çº§ç»´åº¦è®¾ç½®æƒé‡
                    for dim1 in initial_dimensions['level1']:
                        weights['level1'][dim1] = 0.8
                        weights['level2'][dim1] = {}
                        
                        # ä¸ºäºŒçº§ç»´åº¦è®¾ç½®æƒé‡
                        if dim1 in initial_dimensions['level2']:
                            for dim2 in initial_dimensions['level2'][dim1]:
                                weights['level2'][dim1][dim2] = 0.5
                    
                    # ä¿å­˜åˆ°session_state
                    st.session_state.settings['dimensions'] = initial_dimensions
                    st.session_state.settings['weights'] = weights
                    st.session_state.settings['custom_dimensions'] = True
                    
                    # ä¿å­˜è®¾ç½®
                    current_project = st.session_state.get('current_project', 'default')
                    if current_project:
                        session_state.save_settings(current_project)
                    logger.info("æˆåŠŸè‡ªåŠ¨åŠ è½½core_templateså¹¶è®¾ç½®ä¸ºé»˜è®¤ç»´åº¦")
                
                # è®¾ç½®å½“å‰æ¨¡æ¿ä¸ºcore_templates.json
                st.session_state.current_template = 'core_templates.json'
                # è®¾ç½®æ ‡å¿—ï¼Œè¡¨ç¤ºéœ€è¦è‡ªåŠ¨é€‰æ‹©@core_templates.json
                st.session_state.select_core_templates = True
                
                logger.info(f"åˆå§‹åŒ–å®Œæˆï¼šå·²è‡ªåŠ¨åŠ è½½core_templates.jsonæ–‡ä»¶")
            else:
                logger.warning(f"core_templates.jsonæ–‡ä»¶ä¸å­˜åœ¨: {core_template_path}")
            st.session_state.core_templates_loaded = True
        except Exception as e:
            logger.error(f"åŠ è½½core_templates.jsonæ—¶å‡ºé”™: {str(e)}")
            st.session_state.core_templates_loaded = False

    # ---------- ä¿®æ”¹ï¼šå°†æ¨¡æ¿é€‰æ‹©ç§»åˆ°æœ€ä¸Šæ–¹ ----------
    # æ¨¡æ¿ç®¡ç†éƒ¨åˆ†
    st.subheader("é€‰æ‹©æ¨¡æ¿")
    
    # è·å–æ¨¡æ¿åˆ—è¡¨ï¼Œä½¿ç”¨ä»fixed_dimension_editorå¯¼å…¥çš„å‡½æ•°
    template_names = get_template_names()
    
    # ç¡®ä¿æœ‰core_templates.jsonåœ¨åˆ—è¡¨ä¸­å¹¶æ’åœ¨é¦–ä½
    if '@core_templates.json' in template_names:
        template_names.remove('@core_templates.json')
        template_names.insert(0, '@core_templates.json')
    
    # è®¾ç½®é»˜è®¤é€‰æ‹©ä¸ºcore_templates.jsonï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    default_index = 0
    
    # å¦‚æœéœ€è¦è‡ªåŠ¨é€‰æ‹©core_templates.jsonï¼Œæ›´æ–°é»˜è®¤ç´¢å¼•
    if st.session_state.get('select_core_templates', False) and '@core_templates.json' in template_names:
        default_index = template_names.index('@core_templates.json')
        # ä½¿ç”¨å®Œè¿™ä¸ªæ ‡å¿—åæ¸…é™¤å®ƒ
        st.session_state.select_core_templates = False
    
    # é€‰æ‹©æ¨¡æ¿
    selected_template = st.selectbox(
        "é€‰æ‹©æ¨¡æ¿", 
        template_names,
        index=default_index,
        key="template_selector",
        on_change=lambda: st.session_state.update({'need_reload_template': True})
    )
    
    # é¦–æ¬¡åŠ è½½é¡µé¢æ—¶ï¼Œè‡ªåŠ¨åº”ç”¨é€‰ä¸­çš„æ¨¡æ¿
    if 'first_load' not in st.session_state:
        st.session_state.first_load = True
        st.session_state.need_reload_template = True
    
    # é€‰æ‹©æ¨¡æ¿åè‡ªåŠ¨åŠ è½½ç»´åº¦æ¨¡ç‰ˆæ–‡ä»¶
    if st.session_state.get('need_reload_template', False) and selected_template:
        logger.info(f"å¼€å§‹åŠ è½½æ¨¡æ¿: {selected_template}")
        # å‡†å¤‡æ¨¡æ¿æ–‡ä»¶å
        if selected_template.startswith('@'):
            # ç›´æ¥ä½¿ç”¨æ–‡ä»¶åï¼ˆå¤„ç†å¯èƒ½å·²åŒ…å«.jsonçš„æƒ…å†µï¼‰
            if selected_template.endswith('.json'):
                template_file = selected_template[1:]  # å»æ‰@å‰ç¼€
            else:
                template_file = f"{selected_template[1:]}.json"  # å»æ‰@å‰ç¼€å¹¶æ·»åŠ .json
                
            # è·å–æ¨¡æ¿æ•°æ®çš„é”®åä¹Ÿéœ€è¦å¤„ç†
            template_key = selected_template
        else:
            # å°†æ¨¡æ¿åç§°è½¬æ¢ä¸ºæ–‡ä»¶å
            template_file = f"{selected_template.replace(' ', '_')}.json"
            template_key = selected_template
        
        # åŠ è½½æ¨¡æ¿æ•°æ®
        template_data = st.session_state.templates.get(template_key)
        logger.info(f"æ‰¾åˆ°æ¨¡æ¿æ•°æ®é”®: {template_key}, æ•°æ®: {template_data is not None}")
        
        if template_data:
            # åº”ç”¨æ¨¡æ¿åˆ°å½“å‰ç»´åº¦ç»“æ„ï¼Œä½¿ç”¨ä»fixed_dimension_editorå¯¼å…¥çš„å‡½æ•°
            apply_template(template_data)
            st.session_state.current_template = template_file
            
            # ä¿å­˜åˆ°session_state
            st.session_state.settings['dimensions'] = st.session_state.dimensions
            st.session_state.settings['weights'] = st.session_state.weights
            st.session_state.settings['custom_dimensions'] = True
            
            # é‡ç½®ä¿®æ”¹çŠ¶æ€
            st.session_state.has_dimension_changes = False
            
            # å¦‚æœæ˜¯é¦–æ¬¡åŠ è½½ï¼Œä¿å­˜è®¾ç½®åˆ°æ–‡ä»¶
            if st.session_state.get('first_load', False):
                current_project = st.session_state.get('current_project', 'default')
                if current_project:
                    session_state.save_settings(current_project)
                st.session_state.first_load = False
            
            st.success(f"å·²åŠ è½½æ¨¡æ¿: {selected_template}")
            logger.info(f"å·²åŠ è½½æ¨¡æ¿: {selected_template}, æ–‡ä»¶: {template_file}")
        else:
            logger.error(f"æœªæ‰¾åˆ°æ¨¡æ¿æ•°æ®: {selected_template}, é”®: {template_key}")
            available_keys = list(st.session_state.templates.keys())
            logger.error(f"å¯ç”¨çš„æ¨¡æ¿é”®: {available_keys}")
            st.error(f"æ— æ³•åŠ è½½æ¨¡æ¿: {selected_template}")
        
        # é‡ç½®æ ‡å¿—
        st.session_state.need_reload_template = False
    
    st.markdown("---")
    
    # æ¨¡æ¿ç®¡ç†å·¥å…·åŒºåŸŸ
    col1, col2 = st.columns([1, 1])
    
    # å·¦ä¾§ï¼šåˆ›å»ºæ–°æ¨¡æ¿
    with col1:
        with st.expander("åˆ›å»ºæ–°æ¨¡æ¿", expanded=False):
            new_template_name = st.text_input("æ–°æ¨¡æ¿åç§°")
            if st.button("ä¿å­˜ä¸ºæ¨¡æ¿", help="å°†å½“å‰ç»´åº¦ç»“æ„ä¿å­˜ä¸ºæ–°æ¨¡æ¿"):
                if new_template_name:
                    if 'dimensions' in st.session_state:
                        # å°†å½“å‰ç»´åº¦ç»“æ„è½¬æ¢ä¸ºæ¨¡æ¿æ ¼å¼
                        template_data = {}
                        for dim1 in st.session_state.dimensions.get('level1', []):
                            dim2_list = st.session_state.dimensions.get('level2', {}).get(dim1, [])
                            template_data[dim1] = dim2_list
                        
                        # ä¿å­˜æ¨¡æ¿
                        save_template(new_template_name, template_data)
                        st.success(f"å·²å°†å½“å‰ç»´åº¦ç»“æ„ä¿å­˜ä¸ºæ¨¡æ¿: {new_template_name}")
                        logger.info(f"å·²åˆ›å»ºæ–°æ¨¡æ¿: {new_template_name}")
                        
                        # åˆ·æ–°é¡µé¢ä»¥æ›´æ–°æ¨¡æ¿åˆ—è¡¨
                        time.sleep(0.5)
                        st.rerun()
                    else:
                        st.error("å½“å‰ç»´åº¦ç»“æ„æ— æ•ˆï¼Œæ— æ³•ä¿å­˜ä¸ºæ¨¡æ¿")
                else:
                    st.warning("è¯·è¾“å…¥æ¨¡æ¿åç§°")
    
    # å³ä¾§ï¼šåˆ é™¤æ¨¡æ¿æŒ‰é’®
    with col2:
        if selected_template and not selected_template.startswith('@'):
            if st.button("åˆ é™¤å½“å‰æ¨¡æ¿", help="åˆ é™¤é€‰ä¸­çš„æ¨¡æ¿"):
                delete_template(selected_template)
                st.success(f"å·²åˆ é™¤æ¨¡æ¿: {selected_template}")
                logger.info(f"å·²åˆ é™¤æ¨¡æ¿: {selected_template}")
                
                # é‡ç½®å½“å‰æ¨¡æ¿
                if 'current_template' in st.session_state:
                    del st.session_state.current_template
                
                # åˆ·æ–°é¡µé¢ä»¥æ›´æ–°æ¨¡æ¿åˆ—è¡¨
                time.sleep(0.5)
                st.rerun()
    
    st.markdown("---")
    # ---------- ä¿®æ”¹ç»“æŸ ----------
    
    # æ¸²æŸ“ç»´åº¦ç¼–è¾‘å™¨
    st.subheader("ç»´åº¦ç¼–è¾‘å™¨")
    dimensions_data = render_dimension_editor(current_dimensions)
    
    # ä¿å­˜æŒ‰é’®åŒºåŸŸ
    st.subheader("ä¿å­˜ä¸åº”ç”¨")
    
    # æ·»åŠ ç»´åº¦ä¿®æ”¹çŠ¶æ€æŒ‡ç¤º
    has_changes = st.session_state.get('has_dimension_changes', False)
    current_template = st.session_state.get('current_template')
    
    # åˆ›å»ºä¸¤åˆ—å¸ƒå±€
    col1, col2 = st.columns([1, 1])
    
    # ç¬¬ä¸€åˆ—ï¼šä¿å­˜åˆ°é¡¹ç›®
    with col1:
        if st.button("ä¿å­˜åˆ°é¡¹ç›®", type="primary", help="ä¿å­˜å½“å‰ç»´åº¦ç»“æ„åˆ°é¡¹ç›®è®¾ç½®"):
            # ç¡®ä¿dimensions_dataæ˜¯æœ‰æ•ˆçš„ç»“æ„
            if isinstance(dimensions_data, dict) and 'dimensions' in dimensions_data:
                # å°†ç»´åº¦æ•°æ®ä¿å­˜åˆ°settings
                st.session_state.settings['dimensions'] = dimensions_data['dimensions']
                st.session_state.settings['weights'] = dimensions_data['weights']
                st.session_state.settings['custom_dimensions'] = True
                
                # é‡ç½®ä¿®æ”¹çŠ¶æ€
                st.session_state.has_dimension_changes = False
                
                st.success("ç»´åº¦è®¾ç½®å·²ä¿å­˜åˆ°å½“å‰é¡¹ç›®")
            else:
                st.error("ç»´åº¦æ•°æ®æ ¼å¼æ— æ•ˆï¼Œæ— æ³•ä¿å­˜")
                logging.error(f"ç»´åº¦æ•°æ®æ ¼å¼æ— æ•ˆ: {dimensions_data}")
    
    # ç¬¬äºŒåˆ—ï¼šä¿å­˜åˆ°æ¨¡ç‰ˆæŒ‰é’®
    with col2:
        # åªæœ‰åœ¨æœ‰æ›´æ”¹ä¸”æœ‰å½“å‰æ¨¡æ¿æ—¶æ‰æ˜¾ç¤º
        if has_changes and current_template:
            if st.button("ä¿å­˜åˆ°æ¨¡ç‰ˆ", help="å°†ä¿®æ”¹åçš„ç»´åº¦ç»“æ„ä¿å­˜åˆ°æ¨¡ç‰ˆæ–‡ä»¶ä¸­"):
                if isinstance(dimensions_data, dict) and 'dimensions' in dimensions_data:
                    try:
                        # å°†å½“å‰ç»´åº¦ç»“æ„è½¬æ¢ä¸ºæ¨¡æ¿æ ¼å¼
                        template_data = {}
                        for dim1 in dimensions_data['dimensions'].get('level1', []):
                            dim2_list = dimensions_data['dimensions'].get('level2', {}).get(dim1, [])
                            template_data[dim1] = dim2_list
                        
                        # è·å–å½“å‰æ¨¡æ¿åï¼ˆä¸å¸¦æ‰©å±•åï¼‰
                        template_name = os.path.splitext(current_template)[0].replace('_', ' ')
                        
                        # ä¿å­˜åˆ°ä¼šè¯çŠ¶æ€ä¸­çš„æ¨¡æ¿
                        st.session_state.templates[template_name] = template_data
                        
                        # ä¿å­˜åˆ°æ–‡ä»¶
                        template_dir = os.path.join('data', 'dimensions')
                        os.makedirs(template_dir, exist_ok=True)
                        
                        template_path = os.path.join(template_dir, current_template)
                        with open(template_path, 'w', encoding='utf-8') as f:
                            json.dump(template_data, f, ensure_ascii=False, indent=2)
                        
                        # é‡ç½®ä¿®æ”¹çŠ¶æ€
                        st.session_state.has_dimension_changes = False
                        
                        st.success(f"å·²å°†ä¿®æ”¹åçš„ç»´åº¦ç»“æ„ä¿å­˜åˆ°æ¨¡æ¿æ–‡ä»¶ '{current_template}'")
                        logger.info(f"å·²æ›´æ–°æ¨¡æ¿æ–‡ä»¶: {template_path}")
                    except Exception as e:
                        st.error(f"ä¿å­˜æ¨¡æ¿æ—¶å‡ºé”™: {str(e)}")
                        logger.error(f"æ›´æ–°æ¨¡æ¿æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
                else:
                    st.error("ç»´åº¦æ•°æ®æ ¼å¼æ— æ•ˆï¼Œæ— æ³•ä¿å­˜")
    
    # æ˜¾ç¤ºå½“å‰çŠ¶æ€ï¼ˆå¦‚æœæœ‰ä¿®æ”¹ï¼‰
    if has_changes and current_template:
        st.info(f"å½“å‰ç»´åº¦ç»“æ„å·²ä¿®æ”¹ï¼Œæ‚¨å¯ä»¥é€‰æ‹©ä¿å­˜åˆ°é¡¹ç›®æˆ–ä¿å­˜åˆ°æ¨¡ç‰ˆã€‚")
    elif current_template:
        st.caption(f"å½“å‰ä½¿ç”¨æ¨¡æ¿: {current_template}")
    
    # è‡ªåŠ¨åº”ç”¨åˆå§‹å…³é”®ç»´åº¦æ¨¡æ¿ï¼ˆå¦‚æœå½“å‰æ²¡æœ‰ç»´åº¦è®¾ç½®ï¼‰
    if not st.session_state.settings.get('dimensions'):
        if 'initial key dimensions' in st.session_state.templates:
            template_data = st.session_state.templates['initial key dimensions']
            editor.apply_template(template_data)
            dimensions_data = editor.render()
            # ç¡®ä¿dimensions_dataæ˜¯æœ‰æ•ˆçš„ç»“æ„
            if isinstance(dimensions_data, dict) and 'dimensions' in dimensions_data:
                st.session_state.settings['dimensions'] = dimensions_data['dimensions']
                st.session_state.settings['weights'] = dimensions_data['weights']
                st.session_state.settings['custom_dimensions'] = True
                st.rerun()
            else:
                logging.error(f"è‡ªåŠ¨åº”ç”¨æ¨¡æ¿æ—¶ç»´åº¦æ•°æ®æ ¼å¼æ— æ•ˆ: {dimensions_data}")

def show_analysis_page():
    """æ˜¾ç¤ºç»Ÿä¸€çš„è§†é¢‘åˆ†æé¡µé¢"""
    st.header("è§†é¢‘åˆ†æ")
    st.markdown("å¤„ç†è§†é¢‘ï¼Œæå–å†…å®¹å¹¶æŒ‰ç»´åº¦æˆ–å…³é”®è¯è¿›è¡Œåˆ†æï¼Œè‡ªåŠ¨ç”Ÿæˆå®£ä¼ è§†é¢‘ã€‚")
    
    # ç¡®ä¿settingså­˜åœ¨
    if 'settings' not in st.session_state:
        st.session_state.settings = session_state.get_default_settings()
    
    # è¾“å…¥è§†é¢‘URLåŒºåŸŸ
    st.subheader("è¾“å…¥è§†é¢‘URL")
    
    # åˆ›å»ºä¸¤åˆ—å¸ƒå±€ï¼Œå·¦ä¾§æ˜¾ç¤ºURLåˆ—è¡¨ï¼Œå³ä¾§æ˜¾ç¤ºCSVå¯¼å…¥é€‰é¡¹
    url_col1, url_col2 = st.columns([2, 1])
    
    with url_col1:
        # å°†åˆ—è¡¨è½¬æ¢ä¸ºæ–‡æœ¬
        default_urls = "\n".join(st.session_state.settings.get('urls', []))
        
        # ç›´æ¥ä»session_stateè·å–URLåˆ—è¡¨
        current_urls = st.session_state.settings.get('urls', [])
        urls_text = st.text_area(
            "æ¯è¡Œè¾“å…¥ä¸€ä¸ªè§†é¢‘URL",
            value="\n".join(current_urls),
            height=100,
            help="æ”¯æŒå„ç§è§†é¢‘ç½‘ç«™é“¾æ¥æˆ–ç›´æ¥çš„è§†é¢‘æ–‡ä»¶URL"
        )
        
        # å°†æ–‡æœ¬è½¬æ¢å›åˆ—è¡¨å¹¶ä¿å­˜
        if urls_text != default_urls:
            urls = [url.strip() for url in urls_text.split("\n") if url.strip()]
            st.session_state.settings['urls'] = urls
    
    with url_col2:
        st.write("**æ‰¹é‡å¯¼å…¥URL**")
        
        # æ˜¾ç¤ºæ”¯æŒçš„URLæ ¼å¼
        st.caption("æ”¯æŒè§†é¢‘ç›´é“¾(MP4,MOVç­‰)æˆ–å„å¤§è§†é¢‘ç½‘ç«™é“¾æ¥")
        
        # åˆ›å»ºæ¨¡æ¿ä¸‹è½½æŒ‰é’®
        template_csv = generate_url_template_csv()
        st.download_button(
            "ä¸‹è½½URLæ¨¡æ¿",
            template_csv,
            "video_urls_template.csv",
            "text/csv",
            help="ä¸‹è½½CSVæ¨¡æ¿ï¼Œå¡«å…¥æ‚¨çš„è§†é¢‘URLåä¸Šä¼ "
        )
        
        # CSVæ–‡ä»¶ä¸Šä¼ 
        uploaded_file = st.file_uploader(
            "ä¸Šä¼ CSVæ–‡ä»¶å¯¼å…¥URL",
            type=["csv"],
            help="ä¸Šä¼ åŒ…å«è§†é¢‘URLçš„CSVæ–‡ä»¶ï¼ˆæ¯è¡Œä¸€ä¸ªURLï¼‰"
        )
        
        # æä¾›æ–‡ä»¶ä¸Šä¼ æç¤º
        if uploaded_file is None:
            st.write("")  # æ·»åŠ ç©ºé—´
        else:
            try:
                # è°ƒç”¨å¯¼å…¥å‡½æ•°
                new_count, total_count = import_urls_from_csv(uploaded_file)
                if new_count > 0:
                    # ä¿å­˜å½“å‰é¡¹ç›®è®¾ç½®ï¼Œç¡®ä¿URLåˆ—è¡¨è¢«æŒä¹…åŒ–
                    current_project = st.session_state.get('current_project', 'default')
                    session_state.save_settings(current_project)
                    
                    # æ˜¾ç¤ºæˆåŠŸæ¶ˆæ¯
                    st.success(f"æˆåŠŸå¯¼å…¥ {new_count} ä¸ªæ–°URLï¼Œå½“å‰å…±æœ‰ {total_count} ä¸ªURL")
                    
                    # å¼ºåˆ¶åˆ·æ–°é¡µé¢ä»¥æ›´æ–°æ‰€æœ‰çŠ¶æ€
                    st.rerun()
                else:
                    st.warning("æœªæ‰¾åˆ°æœ‰æ•ˆçš„URLæˆ–æ‰€æœ‰URLå·²å­˜åœ¨")
            except Exception as e:
                st.error(f"å¯¼å…¥å¤±è´¥: {str(e)}")
    
    # ç›´æ¥ä»session_stateè·å–URLæ•°é‡
    url_count = len(st.session_state.settings.get('urls', []))
    # æ·»åŠ æ›´å®½æ¾çš„URLæœ‰æ•ˆæ€§æ£€æŸ¥ï¼Œæ¥å—æ›´å¤šè§†é¢‘æ ¼å¼
    video_extensions = ('.mp4', '.mov', '.avi', '.wmv', '.flv', '.mkv', '.webm', '.m4v', '.mpeg', '.mpg', '.3gp')
    valid_urls = [url for url in st.session_state.settings.get('urls', []) 
                 if url.startswith(('http://', 'https://')) and (
                    any(url.lower().endswith(ext) for ext in video_extensions) or 
                    'youtube.com' in url.lower() or 
                    'youtu.be' in url.lower() or
                    'vimeo.com' in url.lower() or
                    'bilibili.com' in url.lower() or
                    not url.lower().split('?')[0].split('/')[-1].find('.')>0  # å¦‚æœURLæ²¡æœ‰æ˜ç¡®çš„æ–‡ä»¶æ‰©å±•åï¼Œä¹Ÿè®¤ä¸ºæ˜¯æœ‰æ•ˆçš„
                 )]
    # ä½¿ç”¨æœ‰æ•ˆURLçš„æ•°é‡æ¥åˆ¤æ–­
    valid_url_count = len(valid_urls)
    
    if url_count > 0:
        if valid_url_count > 0:
            st.success(f"å·²æ·»åŠ  {url_count} ä¸ªè§†é¢‘URLï¼Œå…¶ä¸­ {valid_url_count} ä¸ªæœ‰æ•ˆ")
        else:
            st.warning(f"å·²æ·»åŠ  {url_count} ä¸ªURLï¼Œä½†æ²¡æœ‰è¯†åˆ«åˆ°æœ‰æ•ˆçš„è§†é¢‘URLã€‚æ”¯æŒçš„æ ¼å¼ï¼šMP4, MOV, AVIç­‰æˆ–è§†é¢‘ç½‘ç«™é“¾æ¥")
    else:
        st.warning("è¯·æ·»åŠ è‡³å°‘ä¸€ä¸ªè§†é¢‘URL")
    
    # å¦‚æœæ²¡æœ‰è¾“å…¥URLï¼Œç¦ç”¨åˆ†æé€‰é¡¹å¡
    if url_count == 0:
        st.info("è¯·å…ˆæ·»åŠ è§†é¢‘URLï¼Œç„¶åé€‰æ‹©åˆ†ææ–¹å¼")
        return
    
    # å¦‚æœæœ‰URLï¼Œåˆ™ä¸€å®šæ˜¾ç¤ºåˆ†æé€‰é¡¹å¡
    st.success(f"å¯ä»¥å¼€å§‹åˆ†æ {url_count} ä¸ªè§†é¢‘URL")
    
    # ä½¿ç”¨tabsè¿›è¡Œåˆ†ææ–¹å¼åˆ‡æ¢
    tabs = st.tabs(["ç»´åº¦åˆ†æ", "å…³é”®è¯åˆ†æ"])
    
    # Tab 1: ç»´åº¦åˆ†æ
    with tabs[0]:
        show_dimension_analysis_tab()
    
    # Tab 2: å…³é”®è¯åˆ†æ
    with tabs[1]:
        show_keyword_analysis_tab()

def show_dimension_analysis_tab():
    """ç»´åº¦åˆ†ææ ‡ç­¾é¡µå†…å®¹"""
    st.markdown("### ç»´åº¦åˆ†æ")
    st.markdown("æ ¹æ®é¢„è®¾çš„ç»´åº¦ç»“æ„ï¼Œåˆ†æè§†é¢‘å†…å®¹ï¼Œæå–åŒ¹é…æŒ‡å®šç»´åº¦çš„ç‰‡æ®µã€‚")
    
    # æ·»åŠ å½“å‰ç»´åº¦å±•ç¤ºåŒºåŸŸ
    with st.expander("å½“å‰åˆ†æç»´åº¦", expanded=True):
        # ä»session_stateä¸­è·å–å½“å‰ç»´åº¦è®¾ç½®
        dimensions = st.session_state.settings.get('dimensions', {})
        
        # ç¡®ä¿dimensionså­˜åœ¨åŸºæœ¬ç»“æ„
        if not dimensions or not isinstance(dimensions, dict):
            dimensions = {}
            st.warning("å°šæœªè®¾ç½®ä»»ä½•ç»´åº¦ï¼Œè¯·å‰å¾€ç»´åº¦è®¾ç½®é¡µé¢è¿›è¡Œè®¾ç½®ã€‚")
        else:
            # æ·»åŠ è¯´æ˜æ–‡æœ¬
            st.info("ç»´åº¦åˆ†æå°†åŸºäºä»¥ä¸‹ç»´åº¦ç»“æ„æå–è§†é¢‘ä¸­çš„ç›¸å…³å†…å®¹ã€‚")
            
            # æ˜¾ç¤ºä¸€çº§ç»´åº¦ - å³æ€»æ ‡é¢˜
            level1 = dimensions.get('level1', '')
            if level1:
                st.markdown(f"### {level1}")
                
                # æ˜¾ç¤ºäºŒçº§ç»´åº¦
                level2_dims = dimensions.get('level2', [])
                
                if not level2_dims:
                    st.caption("å½“å‰ä»…è®¾ç½®äº†ä¸€çº§ç»´åº¦æ ‡é¢˜ï¼Œè¯·æ·»åŠ äºŒçº§ç»´åº¦ä»¥ä¾¿è¿›è¡Œåˆ†æã€‚")
                else:
                    # æ˜¾ç¤ºæ‰€æœ‰äºŒçº§ç»´åº¦
                    for i, dim2 in enumerate(level2_dims):
                        # å¦‚æœæ­¤ç»´åº¦å·²è¢«åˆ é™¤ï¼Œåˆ™è·³è¿‡
                        if 'dimension_state' in st.session_state and dim2 in st.session_state.dimension_state.get('deleted_level2', []):
                            continue
                        
                        st.markdown(f"**{i+1}. {dim2}**")
                        
                        # æ·»åŠ åˆ†éš”ç¬¦
                        if i < len(level2_dims) - 1:
                            st.markdown("---")
            else:
                st.warning("å½“å‰ç»´åº¦ç»“æ„æœªè®¾ç½®ä¸€çº§ç»´åº¦ï¼Œè¯·å‰å¾€ç»´åº¦è®¾ç½®é¡µé¢å®Œå–„ã€‚")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # ç›¸ä¼¼åº¦é˜ˆå€¼
        threshold = st.slider(
            "ç›¸ä¼¼åº¦é˜ˆå€¼",
            0.5, 1.0, 
            value=st.session_state.settings.get('threshold', 0.7),
            step=0.05,
            key="dimension_threshold_slider",
            help="è¾ƒé«˜çš„é˜ˆå€¼å°†ç­›é€‰å‡ºæ›´ç›¸å…³çš„ç‰‡æ®µï¼Œä½†å¯èƒ½å‡å°‘åŒ¹é…æ•°é‡"
        )
        st.session_state.settings['threshold'] = threshold
        
        # å¤„ç†å·²ä¿å­˜çš„è®¾ç½®ï¼Œå¦‚æœæ˜¯"ä¸‰çº§ç»´åº¦"åˆ™æ›´æ”¹ä¸º"ç»¼åˆè¯„åˆ†"
        saved_priority = st.session_state.settings.get('priority', 'ç»¼åˆè¯„åˆ†')
        if saved_priority == "ä¸‰çº§ç»´åº¦":
            saved_priority = "ç»¼åˆè¯„åˆ†"
            st.session_state.settings['priority'] = saved_priority
        
        # åŒ¹é…ç»´åº¦ä¼˜å…ˆçº§
        priority = st.selectbox(
            "ç»´åº¦ä¼˜å…ˆçº§",
            ["ä¸€çº§ç»´åº¦", "äºŒçº§ç»´åº¦", "ç»¼åˆè¯„åˆ†"],
            index=["ä¸€çº§ç»´åº¦", "äºŒçº§ç»´åº¦", "ç»¼åˆè¯„åˆ†"].index(saved_priority),
            help="é€‰æ‹©åœ¨åŒ¹é…è¿‡ç¨‹ä¸­ä¼˜å…ˆè€ƒè™‘çš„ç»´åº¦å±‚çº§"
        )
        st.session_state.settings['priority'] = priority
    
    with col2:
        # æ ‡è¯­è®¾ç½®
        slogan = st.text_input(
            "è§†é¢‘ç‰‡å°¾æ ‡è¯­",
            value=st.session_state.settings.get('slogan', ''),
            help="å°†æ˜¾ç¤ºåœ¨è§†é¢‘æœ«å°¾çš„æ–‡æœ¬"
        )
        st.session_state.settings['slogan'] = slogan
        
        # ç‰‡æ®µæ•°é‡é™åˆ¶
        max_clips = st.number_input(
            "æœ€å¤§ç‰‡æ®µæ•°é‡",
            min_value=1,
            max_value=50,
            value=st.session_state.settings.get('max_clips', 10),
            help="æ¯ä¸ªç»´åº¦æœ€å¤šåŒ¹é…çš„è§†é¢‘ç‰‡æ®µæ•°"
        )
        st.session_state.settings['max_clips'] = max_clips
    
    # æ·»åŠ "å¼€å§‹ç»´åº¦åˆ†æ"æŒ‰é’®
    if st.button("å¼€å§‹ç»´åº¦åˆ†æ", type="primary"):
        # æ£€æŸ¥æ˜¯å¦æœ‰ç»´åº¦è®¾ç½®
        dimensions = st.session_state.settings.get('dimensions', {})
        if not dimensions or not isinstance(dimensions, dict) or not dimensions.get('level1'):
            st.error("è¯·å…ˆè®¾ç½®æœ‰æ•ˆçš„ç»´åº¦ç»“æ„ï¼Œå†è¿›è¡Œåˆ†æã€‚")
            return
            
        # è·å–è§†é¢‘URLåˆ—è¡¨
        urls = st.session_state.settings.get('urls', [])
        if not urls:
            st.error("è¯·å…ˆæ·»åŠ è§†é¢‘URLï¼Œå†è¿›è¡Œåˆ†æã€‚")
            return
            
        # æ˜¾ç¤ºè¿›åº¦ä¿¡æ¯
        with st.spinner("æ­£åœ¨åˆ†æè§†é¢‘å†…å®¹..."):
            try:
                # è¿™é‡Œæ·»åŠ ç»´åº¦åˆ†æçš„å®é™…å¤„ç†é€»è¾‘
                # å¯¼å…¥ç›¸å…³æ¨¡å—
                import time  # ä¸´æ—¶ä½¿ç”¨ï¼Œå®é™…åº”ç”¨ä¸­åº”è¯¥å¯¼å…¥å®é™…å¤„ç†æ¨¡å—
                
                # åˆ›å»ºä¸€ä¸ªç¤ºä¾‹è¿›åº¦æ¡
                progress_bar = st.progress(0)
                for i in range(101):
                    time.sleep(0.05)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
                    progress_bar.progress(i)
                
                # æ¨¡æ‹Ÿç”Ÿæˆä¸€äº›ç¤ºä¾‹ç»“æœ
                sample_results = []
                for i, url in enumerate(urls[:3]):  # å¤„ç†å‰3ä¸ªURLä½œä¸ºç¤ºä¾‹
                    for j in range(3):  # æ¯ä¸ªURLç”Ÿæˆ3ä¸ªç»“æœ
                        sample_results.append({
                            'start': float(i * 10 + j * 5),
                            'end': float(i * 10 + j * 5 + 3),
                            'text': f"è¿™æ˜¯æ¥è‡ªè§†é¢‘ {i+1} çš„ç¬¬ {j+1} ä¸ªåŒ¹é…ç‰‡æ®µï¼Œä¸ç»´åº¦ç›¸å…³åº¦ä¸º0.{75+j}",
                            'source': url,
                            'score': 0.75 + j * 0.05,
                            'dimension': f"{dimensions.get('level1')} > {dimensions.get('level2', [''])[min(j, len(dimensions.get('level2', [''])) - 1)]}",
                            'clip_path': None  # å®é™…åº”ç”¨ä¸­åº”è¯¥æœ‰çœŸå®è·¯å¾„
                        })
                
                # ä¿å­˜åˆ°ç»“æœåˆ—è¡¨
                st.session_state.results = sample_results
                
                # æ˜¾ç¤ºæˆåŠŸä¿¡æ¯
                if sample_results:
                    st.success(f"åˆ†æå®Œæˆï¼æ‰¾åˆ° {len(sample_results)} ä¸ªä¸ç»´åº¦ç›¸å…³çš„ç‰‡æ®µã€‚")
                    
                    # æ·»åŠ ä¸€ä¸ªç®€å•çš„ç»“æœé¢„è§ˆ
                    st.subheader("ç»“æœé¢„è§ˆ")
                    for i, result in enumerate(sample_results[:5]):  # åªæ˜¾ç¤ºå‰5ä¸ªç»“æœ
                        # åˆ›å»ºä¸€ä¸ªç¾è§‚çš„ç»“æœå¡ç‰‡
                        with st.container():
                            st.markdown(f"### ç‰‡æ®µ {i+1} (åŒ¹é…åº¦: {result['score']:.2f})")
                            cols = st.columns([3, 2])
                            
                            with cols[0]:
                                # ä»ç»´åº¦ä¿¡æ¯ä¸­æå–äºŒçº§ç»´åº¦
                                dimension_info = result['dimension']
                                if ' > ' in dimension_info:
                                    _, second_level = dimension_info.split(' > ', 1)
                                    st.markdown(f"**ç»´åº¦:** {second_level}")
                                else:
                                    st.markdown(f"**ç»´åº¦:** {dimension_info}")
                                
                                st.markdown(f"**æ¥æº:** {result['source']}")
                                st.markdown(f"**æ—¶é—´:** {result['start']:.1f}s - {result['end']:.1f}s")
                                
                                # æ˜¾ç¤ºç‰‡æ®µæ–‡å­—
                                st.caption(result['text'])
                                
                            with cols[1]:
                                # å¦‚æœæœ‰è§†é¢‘ç‰‡æ®µï¼Œæ˜¾ç¤ºé¢„è§ˆ
                                if result['clip_path'] and os.path.exists(result['clip_path']):
                                    st.video(result['clip_path'])
                                else:
                                    st.info("è§†é¢‘ç‰‡æ®µé¢„è§ˆä¸å¯ç”¨")
                            
                            # æ·»åŠ åˆ†éš”çº¿
                            st.markdown("---")
                    
                    # æ·»åŠ "æŸ¥çœ‹è¯¦ç»†ç»“æœ"æŒ‰é’®
                    if st.button("æŸ¥çœ‹è¯¦ç»†ç»“æœ", key="dim_goto_results", on_click=set_navigate_to_results):
                        # æŒ‰é’®ç‚¹å‡»å¤„ç†ç”± set_navigate_to_results å›è°ƒå‡½æ•°å¤„ç†
                        pass
                else:
                    st.warning("æœªæ‰¾åˆ°ä¸ç»´åº¦ç›¸å…³çš„å†…å®¹ã€‚è¯·å°è¯•è°ƒæ•´ç»´åº¦è®¾ç½®æˆ–é™ä½ç›¸ä¼¼åº¦é˜ˆå€¼ã€‚")
                    
            except Exception as e:
                st.error(f"å¤„ç†å¤±è´¥: {str(e)}")
                import traceback
                st.error(traceback.format_exc())
        
        # æ›¿æ¢æ¨¡æ‹Ÿä»£ç ï¼Œä½¿ç”¨çœŸå®çš„è§†é¢‘å¤„ç†
        try:
            # è·å–è§†é¢‘URLåˆ—è¡¨
            urls = st.session_state.settings.get('urls', [])
            if not urls:
                st.error("è¯·å…ˆæ·»åŠ è§†é¢‘URLï¼Œå†è¿›è¡Œåˆ†æã€‚")
                return
            
            # è·å–ç”¨æˆ·è®¾ç½®
            user_settings = {
                'threshold': threshold,
                'priority': priority,
                'max_clips': max_clips,
                'slogan': slogan
            }
            
            # åˆå§‹åŒ–è§†é¢‘å¤„ç†å™¨
            video_processor = VideoProcessor()
            
            # åˆ›å»ºå¤„ç†é…ç½®
            class ProcessorConfig:
                PROCESS_STEPS = ['subtitles', 'analysis', 'matching']
                DEFAULT_DIMENSIONS = st.session_state.settings.get('dimensions', {
                    'level1': 'å“ç‰Œè®¤çŸ¥',
                    'level2': ['ç›®æ ‡äººç¾¤', 'äº§å“ç‰¹æ€§', 'ä½¿ç”¨åœºæ™¯']
                })
            
            video_processor.config = ProcessorConfig()
            
            # å¤„ç†è§†é¢‘
            results = video_processor.process_pipeline(urls, user_settings)
            
            # å°†ç»“æœè½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨ä»¥ä¾¿äºUIå±•ç¤º
            formatted_results = []
            for result in results:
                formatted_results.append({
                    'start': result.start,
                    'end': result.end,
                    'text': result.text,
                    'score': float(result.score),
                    'source': result.source,
                    'dimension': result.dimension,
                    'clip_path': result.clip_path
                })
            
            # ä¿å­˜åˆ°ä¼šè¯çŠ¶æ€
            st.session_state.results = formatted_results
            
            # æ˜¾ç¤ºç»“æœ
            if formatted_results:
                st.success(f"åˆ†æå®Œæˆï¼æ‰¾åˆ° {len(formatted_results)} ä¸ªä¸ç»´åº¦ç›¸å…³çš„ç‰‡æ®µã€‚")
                
                # æ·»åŠ ä¸€ä¸ªç®€å•çš„ç»“æœé¢„è§ˆ
                st.subheader("ç»“æœé¢„è§ˆ")
                for i, result in enumerate(formatted_results[:5]):  # åªæ˜¾ç¤ºå‰5ä¸ªç»“æœ
                    # åˆ›å»ºä¸€ä¸ªç¾è§‚çš„ç»“æœå¡ç‰‡
                    with st.container():
                        st.markdown(f"### ç‰‡æ®µ {i+1} (åŒ¹é…åº¦: {result['score']:.2f})")
                        cols = st.columns([3, 2])
                        
                        with cols[0]:
                            # ä»ç»´åº¦ä¿¡æ¯ä¸­æå–äºŒçº§ç»´åº¦
                            dimension_info = result['dimension']
                            if ' > ' in dimension_info:
                                _, second_level = dimension_info.split(' > ', 1)
                                st.markdown(f"**ç»´åº¦:** {second_level}")
                            else:
                                st.markdown(f"**ç»´åº¦:** {dimension_info}")
                            
                            st.markdown(f"**æ¥æº:** {result['source']}")
                            st.markdown(f"**æ—¶é—´:** {result['start']:.1f}s - {result['end']:.1f}s")
                            
                            # æ˜¾ç¤ºç‰‡æ®µæ–‡å­—
                            st.caption(result['text'])
                            
                        with cols[1]:
                            # å¦‚æœæœ‰è§†é¢‘ç‰‡æ®µï¼Œæ˜¾ç¤ºé¢„è§ˆ
                            if result['clip_path'] and os.path.exists(result['clip_path']):
                                st.video(result['clip_path'])
                            else:
                                st.info("è§†é¢‘ç‰‡æ®µé¢„è§ˆä¸å¯ç”¨")
                            
                            # æ·»åŠ åˆ†éš”çº¿
                            st.markdown("---")
                    
                    # æ·»åŠ "æŸ¥çœ‹è¯¦ç»†ç»“æœ"æŒ‰é’®
                    if st.button("æŸ¥çœ‹è¯¦ç»†ç»“æœ", key="dim_goto_results", on_click=set_navigate_to_results):
                        # æŒ‰é’®ç‚¹å‡»å¤„ç†ç”± set_navigate_to_results å›è°ƒå‡½æ•°å¤„ç†
                        pass
            else:
                st.warning("æœªæ‰¾åˆ°ä¸ç»´åº¦ç›¸å…³çš„å†…å®¹ã€‚è¯·å°è¯•è°ƒæ•´ç»´åº¦è®¾ç½®æˆ–é™ä½ç›¸ä¼¼åº¦é˜ˆå€¼ã€‚")
                
        except Exception as e:
            st.error(f"å¤„ç†å¤±è´¥: {str(e)}")
            import traceback
            st.error(traceback.format_exc())

def show_keyword_analysis_tab():
    """å…³é”®è¯åˆ†ææ ‡ç­¾é¡µå†…å®¹"""
    # ç¡®ä¿keyword_resultså­˜åœ¨
    if 'keyword_results' not in st.session_state:
        st.session_state.keyword_results = []
        
    st.markdown("### å…³é”®è¯åˆ†æ")
    st.markdown("åˆ†æè§†é¢‘ä¸­ä¸å…³é”®è¯è¯­ä¹‰ç›¸å…³çš„ç‰‡æ®µï¼Œæå–ç¬¦åˆæ¡ä»¶çš„è§†é¢‘å†…å®¹ã€‚")
    
    # å·¦å³å¸ƒå±€ï¼šå·¦ä¾§å‚æ•°åŒºåŸŸï¼Œå³ä¾§ç»“æœé¢„è§ˆ
    col1, col2 = st.columns([1, 1])
    
    with col1:
        # å…³é”®è¯è¾“å…¥åŒº
        keywords = st.text_area(
            "è¯·è¾“å…¥å…³é”®è¯ï¼ˆå¤šä¸ªå…³é”®è¯è¯·ç”¨é€—å·ã€ç©ºæ ¼æˆ–æ¢è¡Œåˆ†éš”ï¼‰",
            placeholder="ä¾‹å¦‚ï¼šå®‰å…¨ã€è¥å…»ã€å“ç‰Œæ•…äº‹",
            height=100
        )
        
        # ç›¸ä¼¼åº¦é˜ˆå€¼
        threshold = st.slider(
            "ç›¸ä¼¼åº¦é˜ˆå€¼",
            0.5, 1.0, 
            value=st.session_state.settings.get('keyword_threshold', 0.7),
            step=0.05,
            key="keyword_threshold_slider",
            help="è¾ƒé«˜çš„é˜ˆå€¼å°†ç­›é€‰å‡ºæ›´ç›¸å…³çš„ç‰‡æ®µï¼Œä½†å¯èƒ½å‡å°‘åŒ¹é…æ•°é‡"
        )
        st.session_state.settings['keyword_threshold'] = threshold
        
        # å¤„ç†æ¨¡å¼
        process_mode = st.radio(
            "å¤„ç†æ¨¡å¼",
            ["å•ç‹¬å¤„ç†æ¯ä¸ªè§†é¢‘", "æ‰¹é‡å¤„ç†æ‰€æœ‰è§†é¢‘"],
            horizontal=True,
            help="å•ç‹¬å¤„ç†æ¨¡å¼å°†ä¸ºæ¯ä¸ªè§†é¢‘å•ç‹¬åˆ†æå…³é”®è¯ï¼›æ‰¹é‡å¤„ç†æ¨¡å¼å°†åŒæ—¶å¤„ç†æ‰€æœ‰è§†é¢‘å¹¶æŒ‰å…³é”®è¯åˆ†ç»„ç»“æœ"
        )
        st.session_state.settings['keyword_process_mode'] = process_mode
        
        # å¤„ç†æŒ‰é’®
        if st.button("å¼€å§‹å…³é”®è¯åˆ†æ", type="primary", disabled=not keywords.strip()):
            # è§£æå…³é”®è¯åˆ—è¡¨
            keyword_list = [k.strip() for k in re.split(r'[,ï¼Œ\s\n]+', keywords) if k.strip()]
            
            # å…³é”®è¯åˆ†æå¤„ç†
            with st.spinner("æ­£åœ¨åˆ†æå…³é”®è¯ç›¸å…³å†…å®¹..."):
                try:
                    # å¯¼å…¥å…³é”®è¯æœç´¢å·¥å…·
                    from keyword_search import KeywordSearchTool
                    
                    # åˆå§‹åŒ–æœç´¢å·¥å…·
                    search_tool = KeywordSearchTool()
                    
                    # è·å–è§†é¢‘URLåˆ—è¡¨
                    urls = st.session_state.settings.get('urls', [])
                    
                    # è·å–å¤„ç†æ¨¡å¼
                    process_mode = st.session_state.settings.get('keyword_process_mode', "å•ç‹¬å¤„ç†æ¯ä¸ªè§†é¢‘")
                    
                    if process_mode == "æ‰¹é‡å¤„ç†æ‰€æœ‰è§†é¢‘":
                        # ä½¿ç”¨æ‰¹é‡å¤„ç†æ¨¡å¼
                        all_results = search_tool.batch_process(urls, keyword_list, threshold)
                        
                        # åˆå¹¶æ‰€æœ‰ç»“æœ
                        results = []
                        for url, url_results in all_results.items():
                            for result in url_results:
                                results.append(result)
                                
                        # é«˜äº®ç»“æœä¸­çš„å…³é”®è¯
                        for result in results:
                            if 'keyword' in result and 'text' in result:
                                result['highlighted_text'] = search_tool.highlight_keywords(
                                    result['text'], 
                                    result['keyword']
                                )
                        
                        # ä¿å­˜ç»“æœ
                        st.session_state.keyword_results = results
                    else:
                        # å•ç‹¬å¤„ç†æ¯ä¸ªè§†é¢‘ï¼ˆåŸé€»è¾‘ï¼‰
                        # ç”Ÿæˆè§†é¢‘ç‰‡æ®µï¼ˆç¤ºä¾‹å®ç°ï¼Œå®é™…åº”ç”¨ä¸­åº”è¯¥ä»è§†é¢‘ä¸­æå–çœŸå®ç‰‡æ®µï¼‰
                        sample_segments = []
                        for i, url in enumerate(urls[:3]):
                            # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œåº”è¯¥åŠ è½½è§†é¢‘å¹¶æå–å­—å¹•æˆ–è½¬å½•å†…å®¹
                            # è¿™é‡Œä½¿ç”¨ç¤ºä¾‹æ•°æ®æ¨¡æ‹Ÿ
                            for j in range(5):  # æ¯ä¸ªURLç”Ÿæˆ5ä¸ªç‰‡æ®µ
                                sample_segments.append({
                                    'start': float(i * 10 + j * 5),
                                    'end': float(i * 10 + j * 5 + 3),
                                    'text': f"è¿™æ˜¯æ¥è‡ªè§†é¢‘ {i+1} çš„ç¬¬ {j+1} ä¸ªç‰‡æ®µã€‚å®ƒåŒ…å«å…³äºäº§å“ä»‹ç»ã€{['å“ç‰Œæ•…äº‹', 'åŠŸèƒ½ç‰¹ç‚¹', 'ç”¨æˆ·è¯„ä»·', 'è¡Œä¸šè¶‹åŠ¿', 'ä½¿ç”¨åœºæ™¯'][j]}ç­‰å†…å®¹ã€‚è¿™æ˜¯ä¸€ä¸ªç”¨äºæµ‹è¯•å…³é”®è¯åŒ¹é…åŠŸèƒ½çš„ç¤ºä¾‹ã€‚",
                                    'source': url,
                                    'clip_path': None  # å®é™…åº”ç”¨ä¸­åº”è¯¥æœ‰çœŸå®è·¯å¾„
                                })
                        
                        # è°ƒç”¨å…³é”®è¯åˆ†æåŠŸèƒ½
                        results = search_tool.search_by_keywords(
                            sample_segments,
                            keyword_list,
                            threshold
                        )
                        
                        # é«˜äº®ç»“æœä¸­çš„å…³é”®è¯
                        for result in results:
                            if 'keyword' in result and 'text' in result:
                                result['highlighted_text'] = search_tool.highlight_keywords(
                                    result['text'], 
                                    result['keyword']
                                )
                        
                        # ä¿å­˜ç»“æœ
                        st.session_state.keyword_results = results
                    
                    if results:
                        st.success(f"åˆ†æå®Œæˆï¼æ‰¾åˆ° {len(results)} ä¸ªä¸å…³é”®è¯ç›¸å…³çš„ç‰‡æ®µã€‚")
                    else:
                        st.warning("æœªæ‰¾åˆ°ä¸å…³é”®è¯ç›¸å…³çš„å†…å®¹ã€‚è¯·å°è¯•é™ä½ç›¸ä¼¼åº¦é˜ˆå€¼æˆ–ä½¿ç”¨ä¸åŒçš„å…³é”®è¯ã€‚")
                    
                    # ä¿å­˜åˆ°ç»“æœç®¡ç†ä¸­
                    st.session_state.results = st.session_state.keyword_results
                    session_state.save_results(st.session_state.keyword_results)
                    
                except Exception as e:
                    st.error(f"å¤„ç†å¤±è´¥: {str(e)}")
                    import traceback
                    st.error(traceback.format_exc())
    
    with col2:
        # ç»“æœé¢„è§ˆåŒº
        if st.session_state.keyword_results:
            st.subheader("åˆ†æç»“æœ")
            
            # è·å–å¤„ç†æ¨¡å¼
            process_mode = st.session_state.settings.get('keyword_process_mode', "å•ç‹¬å¤„ç†æ¯ä¸ªè§†é¢‘")
            
            # æŒ‰ä¸åŒæ–¹å¼åˆ†ç»„æ˜¾ç¤ºç»“æœ
            if process_mode == "æ‰¹é‡å¤„ç†æ‰€æœ‰è§†é¢‘":
                # æŒ‰å…³é”®è¯åˆ†ç»„
                keyword_groups = {}
                for segment in st.session_state.keyword_results:
                    kw = segment.get('keyword', 'æœªçŸ¥')
                    if kw not in keyword_groups:
                        keyword_groups[kw] = []
                    keyword_groups[kw].append(segment)
                
                # éå†æ¯ä¸ªå…³é”®è¯ç»„
                for keyword, segments in keyword_groups.items():
                    with st.expander(f"å…³é”®è¯: {keyword} ({len(segments)}ä¸ªç‰‡æ®µ)", expanded=True):
                        for i, segment in enumerate(segments):
                            # ä½¿ç”¨å¡ç‰‡å¼è®¾è®¡
                            st.markdown(f"""
                            <div style="border-left:3px solid #4CAF50; padding:10px; margin-bottom:10px; background-color:#f8f9fa;">
                                <div style="color:#4CAF50;font-weight:bold;">ç‰‡æ®µ {i+1} (åŒ¹é…åº¦: {segment['score']:.2f})</div>
                                <div>æ¥æº: {segment['source']}</div>
                                <div>æ—¶é—´: {segment['start']:.1f}s - {segment['end']:.1f}s</div>
                                <div style="margin-top:5px;padding:5px;background-color:#ffffff;">
                                    {segment.get('highlighted_text', segment['text'])}
                                </div>
                            </div>
                            """, unsafe_allow_html=True)
            else:
                # æŒ‰è§†é¢‘æºåˆ†ç»„
                source_groups = {}
                for segment in st.session_state.keyword_results:
                    src = segment['source']
                    if src not in source_groups:
                        source_groups[src] = []
                    source_groups[src].append(segment)
                
                # éå†æ¯ä¸ªè§†é¢‘æº
                for source, segments in source_groups.items():
                    # æ˜¾ç¤ºç®€çŸ­çš„è§†é¢‘æºURL
                    source_display = source
                    if len(source_display) > 40:
                        source_display = source_display[:20] + "..." + source_display[-17:]
                    
                    with st.expander(f"è§†é¢‘: {source_display} ({len(segments)}ä¸ªç‰‡æ®µ)", expanded=True):
                        for i, segment in enumerate(segments):
                            # ä½¿ç”¨å¡ç‰‡å¼è®¾è®¡
                            st.markdown(f"""
                            <div style="border-left:3px solid #4CAF50; padding:10px; margin-bottom:10px; background-color:#f8f9fa;">
                                <div style="color:#4CAF50;font-weight:bold;">ç‰‡æ®µ {i+1} (åŒ¹é…åº¦: {segment['score']:.2f})</div>
                                <div>å…³é”®è¯: {segment.get('keyword', 'æœªçŸ¥')}</div>
                                <div>æ—¶é—´: {segment['start']:.1f}s - {segment['end']:.1f}s</div>
                                <div style="margin-top:5px;padding:5px;background-color:#ffffff;">
                                    {segment.get('highlighted_text', segment['text'])}
                                </div>
                            </div>
                            """, unsafe_allow_html=True)
            
            # è·³è½¬æŒ‰é’®
            if st.button("æŸ¥çœ‹è¯¦ç»†ç»“æœ", key="kw_goto_results"):
                st.session_state.navigate_to_page = "ç»“æœç®¡ç†"
        else:
            # æç¤ºè¾“å…¥å…³é”®è¯
            st.subheader("ç»“æœé¢„è§ˆ")
            st.info("è¯·è¾“å…¥å…³é”®è¯å¹¶ç‚¹å‡»\"å¼€å§‹å…³é”®è¯åˆ†æ\"æŒ‰é’®æ¥æŸ¥æ‰¾ç›¸å…³è§†é¢‘ç‰‡æ®µ")
            
            # åœ¨ç©ºç™½åŒºåŸŸæ˜¾ç¤ºæç¤ºå›¾æ ‡æˆ–è¯´æ˜
            st.markdown("""
            <div style="text-align:center; margin-top:50px; color:#757575;">
                <div style="font-size:60px;">ğŸ”</div>
                <p>è¾“å…¥å…³é”®è¯ï¼ŒæŸ¥æ‰¾è§†é¢‘ä¸­çš„ç›¸å…³å†…å®¹</p>
            </div>
            """, unsafe_allow_html=True)

def show_results_page():
    """æ˜¾ç¤ºç»“æœç®¡ç†é¡µé¢"""
    st.header("ç»“æœç®¡ç†")
    st.markdown("æŸ¥çœ‹å’Œå¯¼å‡ºå¤„ç†ç»“æœï¼Œç®¡ç†ç”Ÿæˆçš„è§†é¢‘ç‰‡æ®µå’Œåˆ†ææ•°æ®ã€‚")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ç»“æœ
    if 'results' not in st.session_state or not st.session_state.results:
        st.warning("å°šæœªæœ‰åˆ†æç»“æœï¼Œè¯·å…ˆè¿›è¡Œè§†é¢‘åˆ†æã€‚")
        
        if st.button("å‰å¾€è§†é¢‘åˆ†æ"):
            st.session_state.current_page = "è§†é¢‘åˆ†æ"
            st.rerun()
            
        return
    
    # ç»“æœæ‘˜è¦
    st.subheader("ç»“æœæ‘˜è¦")
    
    results = st.session_state.results
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("åŒ¹é…ç‰‡æ®µæ•°", len(results))
    
    with col2:
        avg_score = np.mean([r.get('score', 0) for r in results])
        st.metric("å¹³å‡åŒ¹é…åˆ†æ•°", f"{avg_score:.2f}")
    
    with col3:
        total_duration = sum([r.get('end', 0) - r.get('start', 0) for r in results])
        st.metric("æ€»æ—¶é•¿", f"{total_duration:.1f}ç§’")
    
    # æ·»åŠ åˆ†ææè¿°
    st.subheader("åˆ†ææè¿°")
    st.markdown("ä»¥ä¸‹æ˜¯è§†é¢‘ç‰‡æ®µæŒ‰ç»´åº¦å’Œå…³é”®è¯ç»„ç»‡çš„åˆ†æç»“æœï¼ŒæŒ‰åŒ¹é…åˆ†æ•°ä»é«˜åˆ°ä½æ’åºã€‚")
    
    # æŒ‰ç»´åº¦å’Œå…³é”®è¯ç»„ç»‡ç»“æœ
    dimension_keyword_mapping = {}
    
    # æ”¶é›†ç»´åº¦å’Œå…³é”®è¯ä¿¡æ¯
    for seg in results:
        dimension = seg.get('dimension', 'æœªåˆ†ç±»')
        keyword = seg.get('keyword', 'æœªçŸ¥å…³é”®è¯')
        
        key = f"{dimension}ï¼šã€{keyword}ã€‘"
        if key not in dimension_keyword_mapping:
            dimension_keyword_mapping[key] = []
        
        dimension_keyword_mapping[key].append(seg)
    
    # æ’åºå¹¶æ˜¾ç¤ºç»“æœ
    for key, segments in dimension_keyword_mapping.items():
        # æŒ‰åŒ¹é…åˆ†æ•°ä»é«˜åˆ°ä½æ’åº
        segments.sort(key=lambda x: x.get('score', 0), reverse=True)
        
        # æ˜¾ç¤ºç»´åº¦å’Œå…³é”®è¯
        st.markdown(f"### {key}")
        
        # ä¸ºæ¯ä¸ªåˆ†ç»„åˆ›å»ºä¸€ä¸ªå¯æŠ˜å çš„éƒ¨åˆ†
        with st.expander(f"æŸ¥çœ‹ {len(segments)} ä¸ªåŒ¹é…ç‰‡æ®µ", expanded=True):
            for i, seg in enumerate(segments):
                score = seg.get('score', 0)
                source = seg.get('source', '')
                start = seg.get('start', 0)
                end = seg.get('end', 0)
                text = seg.get('text', '')
                
                st.markdown(f"**[{i+1}] åŒ¹é…åˆ†æ•°: {score:.2f}**")
                st.markdown(f"- **è§†é¢‘URL**: {source}")
                st.markdown(f"- **æ—¶é—´æ®µ**: {start:.1f}ç§’ - {end:.1f}ç§’")
                st.markdown(f"- **å†…å®¹æè¿°**: {text}")
                
                # ä¸ºæ¯ä¸ªç‰‡æ®µæ·»åŠ ä¸€ä¸ªæ¨ªçº¿åˆ†éš”ï¼Œé™¤äº†æœ€åä¸€ä¸ª
                if i < len(segments) - 1:
                    st.markdown("---")
    
    # è¯¦ç»†é¢„è§ˆ
    st.subheader("è¯¦ç»†é¢„è§ˆ")
    
    # é€‰æ‹©ç‰‡æ®µ
    selected_idx = st.selectbox(
        "é€‰æ‹©ç‰‡æ®µæŸ¥çœ‹è¯¦æƒ…",
        range(len(results)),
        format_func=lambda i: f"ç‰‡æ®µ {i+1}: {results[i].get('text', '')[:30]}..."
    )
    
    if selected_idx is not None:
        seg = results[selected_idx]
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.subheader(f"ç‰‡æ®µ {selected_idx+1}")
            st.write(f"**æ—¶é—´æ®µ**: {seg.get('start', 0):.1f}-{seg.get('end', 0):.1f}ç§’")
            st.write(f"**åŒ¹é…åˆ†æ•°**: {seg.get('score', 0):.2f}")
            
            # æ˜¾ç¤ºç»´åº¦ä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if 'dimension' in seg and seg.get('dimension'):
                st.write(f"**ç»´åº¦**: {seg.get('dimension', 'æœªçŸ¥')}")
            
            # æ˜¾ç¤ºå…³é”®è¯ä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if 'keyword' in seg:
                st.write(f"**å…³é”®è¯**: {seg.get('keyword', 'æœªçŸ¥')}")
            
            st.write(f"**æ–‡æœ¬å†…å®¹**:")
            # å¦‚æœå­˜åœ¨é«˜äº®æ–‡æœ¬ï¼Œåˆ™ä½¿ç”¨é«˜äº®ç‰ˆæœ¬
            if 'highlighted_text' in seg:
                st.markdown(seg.get('highlighted_text', ''), unsafe_allow_html=True)
            else:
                st.info(seg.get('text', ''))
            
            # æ’­æ”¾è§†é¢‘ç‰‡æ®µï¼ˆå¦‚æœæœ‰å¯ç”¨çš„ç‰‡æ®µæ–‡ä»¶ï¼‰
            st.write("**è§†é¢‘é¢„è§ˆ**:")
            if 'clip_path' in seg and seg['clip_path'] and os.path.exists(seg['clip_path']):
                st.video(seg['clip_path'])
            else:
                # å¦‚æœæ²¡æœ‰å®é™…ç‰‡æ®µæ–‡ä»¶ï¼Œä½¿ç”¨é™æ€é¢„è§ˆå›¾
                # åˆ›å»ºé¢„è§ˆç»„ä»¶
                preview = VideoPreview()
                preview_img = preview._generate_segment_preview(
                    seg, 
                    f"ç‰‡æ®µ {selected_idx+1}", 
                    st.session_state.settings
                )
                
                if preview_img:
                        st.image(preview_img, use_container_width=True)
                else:
                    st.warning("æ— æ³•åŠ è½½è§†é¢‘é¢„è§ˆ")
        
        with col2:
            st.write("**æ¥æº**:")
            st.code(seg.get('source', ''))
            
            st.write("**ç»´åº¦åŒ¹é…**:")
            
            # ä½¿ç”¨å®é™…çš„ç»´åº¦ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
            if 'dimension' in seg and seg.get('dimension', ''):
                dimension_parts = seg.get('dimension', '').split(' > ')
                if len(dimension_parts) >= 2:
                    st.write(f"- **{dimension_parts[0]}**: {dimension_parts[1]}")
                else:
                    st.write(f"- **ç»´åº¦**: {seg.get('dimension', 'æœªçŸ¥')}")
            else:
                # é»˜è®¤ç»´åº¦æ•°æ®
                st.write("- **ç»´åº¦**: æœªåˆ†ç±»")
            
            # æ·»åŠ ä¸‹è½½æŒ‰é’®
            if 'clip_path' in seg and seg['clip_path'] and os.path.exists(seg['clip_path']):
                # è¯»å–æ–‡ä»¶å†…å®¹ï¼Œç”¨äºä¸‹è½½
                with open(seg['clip_path'], 'rb') as f:
                    clip_bytes = f.read()
                
                # è·å–æ–‡ä»¶å
                clip_filename = os.path.basename(seg['clip_path'])
                
                st.download_button(
                    label="ä¸‹è½½ç‰‡æ®µ",
                    data=clip_bytes,
                    file_name=clip_filename,
                    mime="video/mp4",
                    key=f"download_clip_{selected_idx}"
                )
    
    # å¯¼å‡ºç»“æœ
    st.subheader("å¯¼å‡ºç»“æœ")
    
    # å‡†å¤‡å¯¼å‡ºæ•°æ® - ç›´æ¥ä½¿ç”¨JSONæ ¼å¼ï¼ŒæŒ‰ç…§ç»´åº¦å’Œå…³é”®è¯ç»„ç»‡
    organized_data = {}
    for dimension_key, segments in dimension_keyword_mapping.items():
        organized_data[dimension_key] = []
        for seg in segments:
            item = {
                "score": seg.get('score', 0),
                "source": seg.get('source', ''),
                "start": seg.get('start', 0),
                "end": seg.get('end', 0),
                "text": seg.get('text', '')  # ç¡®ä¿åŒ…å«æ–‡æœ¬å†…å®¹
            }
            
            # æ·»åŠ å…³é”®è¯ä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if 'keyword' in seg:
                item["keyword"] = seg.get('keyword', '')
            
            # æ·»åŠ ç»´åº¦ä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if 'dimension' in seg:
                item["dimension"] = seg.get('dimension', '')
            
            organized_data[dimension_key].append(item)
    
    # å°†æ•°æ®è½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²
    json_str = json.dumps(organized_data, ensure_ascii=False, indent=2)
    
    # åˆ†ä¸¤åˆ—æ˜¾ç¤º
    col1, col2 = st.columns(2)
    
    with col1:
        # æ˜¾ç¤ºJSONæ ¼å¼è¯´æ˜
        st.info("JSONæ ¼å¼åŒ…å«å®Œæ•´çš„æ–‡æœ¬å†…å®¹å’Œå…³é”®è¯ä¿¡æ¯")
        
        # ç›´æ¥æ˜¾ç¤ºä¸‹è½½æŒ‰é’®ï¼Œæ— éœ€é¢å¤–ç‚¹å‡»
        st.download_button(
            "ä¸‹è½½JSON",
            json_str,
            "analysis_results.json",
            "application/json",
            key="download_json",
            use_container_width=True
        )
    
    with col2:
        # åœ¨é¡µé¢ä¸Šç›´æ¥æ˜¾ç¤ºJSONç»“æœçš„æ‘˜è¦
        st.info("é¢„è§ˆJSONç»“æœï¼ˆç‚¹å‡»å±•å¼€æŸ¥çœ‹å®Œæ•´å†…å®¹ï¼‰")
        with st.expander("JSONå†…å®¹", expanded=False):
            st.json(organized_data)

# CSVæ–‡ä»¶å¯¼å…¥URLå·¥å…·å‡½æ•°
def import_urls_from_csv(uploaded_file):
    """
    ä»ä¸Šä¼ çš„CSVæ–‡ä»¶ä¸­å¯¼å…¥URLåˆ—è¡¨
    
    å‚æ•°:
        uploaded_file: Streamlitä¸Šä¼ çš„CSVæ–‡ä»¶å¯¹è±¡
        
    è¿”å›:
        å¯¼å…¥URLæ•°é‡ï¼Œæ›´æ–°åçš„æ€»URLæ•°é‡
    """
    try:
        # è¯»å–CSVæ–‡ä»¶ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰
        new_urls = []
        
        # å°è¯•å¤šç§è§£ææ–¹å¼
        for encoding in ['utf-8-sig', 'utf-8', 'gbk', 'latin-1']:
            try:
                # é‡ç½®æ–‡ä»¶æŒ‡é’ˆ
                uploaded_file.seek(0)
                
                # å°è¯•è¯»å–å¸¦headerçš„æ ¼å¼
                df = pd.read_csv(uploaded_file, encoding=encoding)
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«urlåˆ—
                if 'url' in df.columns:
                    # åŒåˆ—æ ¼å¼ï¼Œæå–urlåˆ—
                    for idx, row in df.iterrows():
                        url = str(row['url']).strip()
                        # æ›´å®½æ¾çš„URLéªŒè¯ï¼Œåªè¦ä»¥http://æˆ–https://å¼€å¤´
                        if url and (url.startswith('http://') or url.startswith('https://')):
                            new_urls.append(url)
                    break
                else:
                    # å•åˆ—æ ¼å¼ï¼Œå‡è®¾URLåœ¨ç¬¬ä¸€åˆ—
                    for idx, row in df.iterrows():
                        url = str(row[0]).strip() if len(row) > 0 else ""
                        # æ›´å®½æ¾çš„URLéªŒè¯ï¼Œåªè¦ä»¥http://æˆ–https://å¼€å¤´
                        if url and (url.startswith('http://') or url.startswith('https://')):
                            new_urls.append(url)
                    break
            except Exception as e:
                # ç»§ç»­å°è¯•ä¸‹ä¸€ç§ç¼–ç æ ¼å¼
                logging.warning(f"ä½¿ç”¨ç¼–ç  {encoding} è§£æCSVå¤±è´¥: {str(e)}")
                continue
        
        # å¦‚æœä¸Šé¢çš„æ–¹æ³•éƒ½å¤±è´¥ï¼Œå°è¯•æ— headerçš„å•åˆ—æ ¼å¼
        if not new_urls:
            for encoding in ['utf-8-sig', 'utf-8', 'gbk', 'latin-1']:
                try:
                    # é‡ç½®æ–‡ä»¶æŒ‡é’ˆ
                    uploaded_file.seek(0)
                    
                    # å°è¯•è¯»å–æ— headerçš„æ ¼å¼
                    df = pd.read_csv(uploaded_file, header=None, encoding=encoding)
                    for idx, row in df.iterrows():
                        url = str(row[0]).strip()
                        # æ›´å®½æ¾çš„URLéªŒè¯ï¼Œåªè¦ä»¥http://æˆ–https://å¼€å¤´
                        if url and (url.startswith('http://') or url.startswith('https://')):
                            new_urls.append(url)
                    break
                except Exception as e:
                    # ç»§ç»­å°è¯•ä¸‹ä¸€ç§ç¼–ç æ ¼å¼
                    logging.warning(f"ä½¿ç”¨ç¼–ç  {encoding} å’Œæ— headeræ¨¡å¼è§£æCSVå¤±è´¥: {str(e)}")
                    continue
        
        if new_urls:
            # åˆå¹¶å»é‡
            current_urls = set(st.session_state.settings.get('urls', []))
            current_urls.update(new_urls)
            all_urls = list(current_urls)
            
            # æ›´æ–°session_state
            st.session_state.settings['urls'] = all_urls
            return len(new_urls), len(all_urls)
        else:
            logging.warning("æœªåœ¨CSVæ–‡ä»¶ä¸­æ‰¾åˆ°æœ‰æ•ˆçš„URL")
            return 0, 0
    except Exception as e:
        logging.error(f"CSVè§£æå¤±è´¥ï¼Œè¯¦ç»†é”™è¯¯: {str(e)}")
        raise Exception(f"CSVæ–‡ä»¶è§£æå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼ã€‚é”™è¯¯è¯¦æƒ…: {str(e)}")

def generate_url_template_csv():
    """
    ç”ŸæˆURLæ¨¡æ¿CSVæ–‡ä»¶
    
    è¿”å›:
        bytes: CSVæ–‡ä»¶å†…å®¹
    """
    import io
    import csv
    
    # åˆ›å»ºå†…å­˜æ–‡ä»¶
    output = io.StringIO()
    writer = csv.writer(output)
    
    # å†™å…¥ç¤ºä¾‹URL
    writer.writerow(["https://your-bucket.oss-cn-beijing.aliyuncs.com/videos/example1.mp4"])
    writer.writerow(["https://your-bucket.oss-cn-beijing.aliyuncs.com/videos/example2.mp4"])
    writer.writerow(["https://your-bucket.oss-cn-beijing.aliyuncs.com/videos/example3.mp4"])
    
    # è·å–CSVå†…å®¹
    content = output.getvalue()
    output.close()
    
    return content.encode('utf-8')

# ---- æ–°å¢ï¼šæŒ‰é’®ç‚¹å‡»å›è°ƒå‡½æ•° ----
def set_navigate_to_results():
    st.session_state.navigate_to_page = "ç»“æœç®¡ç†"
# ---- ç»“æŸæ–°å¢ ----

if __name__ == "__main__":
    try:
        main()
    except RuntimeError as e:
        if "Tried to instantiate class '__path__._path'" in str(e):
            logging.error("PyTorchç±»è·¯å¾„é”™è¯¯ï¼Œè¿™å¯èƒ½æ˜¯ç”±äºPyTorchä¸Python 3.13çš„å…¼å®¹æ€§é—®é¢˜å¯¼è‡´")
            st.error("åº”ç”¨ç¨‹åºå¯åŠ¨å¤±è´¥: PyTorchä¸Pythonç‰ˆæœ¬ä¸å…¼å®¹ã€‚è¯·è€ƒè™‘ä½¿ç”¨Python 3.8-3.10ç‰ˆæœ¬ã€‚")
        else:
            logging.error(f"åº”ç”¨ç¨‹åºé”™è¯¯: {str(e)}")
            st.error(f"åº”ç”¨ç¨‹åºå‘ç”Ÿé”™è¯¯: {str(e)}")
    except Exception as e:
        logging.error(f"æœªå¤„ç†çš„å¼‚å¸¸: {str(e)}", exc_info=True)
        st.error(f"åº”ç”¨ç¨‹åºå‘ç”Ÿæœªå¤„ç†çš„å¼‚å¸¸: {str(e)}")
